{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "super-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:61741</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:61740/status' target='_blank'>http://127.0.0.1:61740/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.43 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:61741' processes=4 threads=8, memory=8.43 GB>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dask_df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import pickle\n",
    "from distributed import Client\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import Booster\n",
    "from lightgbm import plot_importance\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# suppress warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demonstrated-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function identifies the smallest data type that can hold the largest value in a numeric dataframe column\n",
    "# takes in a list of triads (column header, current data type, maximum column value)\n",
    "# returns a dictionary of column header as key and datatype as value\n",
    "\n",
    "def identify_numeric_type(list):\n",
    "    \n",
    "    new_type = []\n",
    "    \n",
    "    for data_head, data_type, data_max in list:\n",
    "        if 'int' in str(data_type):\n",
    "            if data_max < np.iinfo(np.int8).max:\n",
    "                new_type.append((data_head, 'int8'))\n",
    "            elif data_max < np.iinfo(np.int16).max:\n",
    "                new_type.append((data_head, 'int16'))\n",
    "            elif data_max < np.iinfo(np.int32).max:\n",
    "                new_type.append((data_head, 'int32'))\n",
    "            elif data_max < np.iinfo(np.int64).max:\n",
    "                new_type.append((data_head, 'int64'))\n",
    "        elif 'float' in str(data_type):\n",
    "            if data_max < np.finfo(np.float16).max:\n",
    "                new_type.append((data_head, 'float16'))\n",
    "            elif data_max < np.finfo(np.float32).max:\n",
    "                new_type.append((data_head, 'float32'))\n",
    "            elif data_max < np.finfo(np.float64).max:\n",
    "                new_type.append((data_head, 'float64'))\n",
    "                \n",
    "    return dict(new_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "multiple-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2661777 entries, 2013-12-04 to 2016-04-24\n",
      "Columns: 41 entries, store_id to variance_trend_lag_7\n",
      "dtypes: float64(18), int64(15), object(8)\n",
      "memory usage: 852.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 85372 entries, 2016-04-25 to 2016-05-22\n",
      "Columns: 41 entries, store_id to variance_trend_lag_7\n",
      "dtypes: float64(18), int64(15), object(8)\n",
      "memory usage: 27.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# train and test dataframes are around 852.9 MB and 27.4 MB in size\n",
    "\n",
    "train = dask_df.read_csv('./m5-forecasting-accuracy/train_test_split/train/*', header = 'infer', \\\n",
    "                         parse_dates = ['date']).compute().set_index('date')\n",
    "train.info(verbose = False)\n",
    "\n",
    "test = dask_df.read_csv('./m5-forecasting-accuracy/train_test_split/test/*', header = 'infer', \\\n",
    "                        parse_dates = ['date']).compute().set_index('date')\n",
    "test.info(verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lonely-walker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2661777 entries, 2013-12-04 to 2016-04-24\n",
      "Columns: 40 entries, store_id to variance_trend_lag_7\n",
      "dtypes: float16(18), int16(9), int8(5), object(8)\n",
      "memory usage: 332.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 85372 entries, 2016-04-25 to 2016-05-22\n",
      "Columns: 40 entries, store_id to variance_trend_lag_7\n",
      "dtypes: float16(18), int16(3), int8(11), object(8)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# converting numeric type columns to minimal datatypes to reduce storage\n",
    "\n",
    "train = train.drop('day', axis = 1)\n",
    "test = test.drop('day', axis = 1)\n",
    "\n",
    "numeric_columns = train.select_dtypes(include = np.number).columns.tolist()\n",
    "\n",
    "data_head = train.loc[:, numeric_columns].columns.to_list()\n",
    "data_type = train.loc[:, numeric_columns].dtypes.to_list()\n",
    "data_max = train.loc[:, numeric_columns].max().to_list()\n",
    "data_list = np.stack([data_head, data_type, data_max], axis = 1)\n",
    "\n",
    "train_type_dict = identify_numeric_type(data_list)\n",
    "train = train.astype(train_type_dict)\n",
    "\n",
    "data_head = test.loc[:, numeric_columns].columns.to_list()\n",
    "data_type = test.loc[:, numeric_columns].dtypes.to_list()\n",
    "data_max = test.loc[:, numeric_columns].max().to_list()\n",
    "data_list = np.stack([data_head, data_type, data_max], axis = 1)\n",
    "\n",
    "test_type_dict = identify_numeric_type(data_list)\n",
    "test = test.astype(test_type_dict)\n",
    "\n",
    "# it reduces the space used by train dataframe to 332.5 MB\n",
    "train.info(verbose = False)\n",
    "\n",
    "# it reduces the space used by test dataframe to 10.2 MB\n",
    "test.info(verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cross-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding values in all non-numeric type columns to numbers\n",
    "# saving the LabelEncoder objects to disk to use them for decoding later\n",
    "\n",
    "other_columns = train.select_dtypes(exclude = np.number).columns.tolist()\n",
    "\n",
    "for column in other_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    train[column] = label_encoder.fit_transform(train[column])\n",
    "    test[column] = label_encoder.transform(test[column])\n",
    "    pickle.dump(label_encoder, open('./Pickle/label_encoder_' + column + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "similar-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training, validation, and testing sets into features and target variable\n",
    "\n",
    "X_train = train[train.index < '2016-3-28'].drop('units_sold', axis = 1)\n",
    "y_train = train[train.index < '2016-3-28']['units_sold']\n",
    "\n",
    "X_validation = train[train.index >= '2016-3-28'].drop('units_sold', axis = 1)\n",
    "y_validation = train[train.index >= '2016-3-28']['units_sold']\n",
    "\n",
    "X_test = test.drop('units_sold', axis = 1)\n",
    "y_test = test['units_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "continued-iraqi",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[1]\ttraining's rmse: 3.76023\tvalid_1's rmse: 3.45158\n",
      "[2]\ttraining's rmse: 3.73757\tvalid_1's rmse: 3.42874\n",
      "[3]\ttraining's rmse: 3.71597\tvalid_1's rmse: 3.40682\n",
      "[4]\ttraining's rmse: 3.69352\tvalid_1's rmse: 3.3841\n",
      "[5]\ttraining's rmse: 3.67099\tvalid_1's rmse: 3.36136\n",
      "[6]\ttraining's rmse: 3.648\tvalid_1's rmse: 3.33833\n",
      "[7]\ttraining's rmse: 3.62462\tvalid_1's rmse: 3.31485\n",
      "[8]\ttraining's rmse: 3.60196\tvalid_1's rmse: 3.29182\n",
      "[9]\ttraining's rmse: 3.57857\tvalid_1's rmse: 3.26842\n",
      "[10]\ttraining's rmse: 3.55479\tvalid_1's rmse: 3.2448\n",
      "[11]\ttraining's rmse: 3.53058\tvalid_1's rmse: 3.22075\n",
      "[12]\ttraining's rmse: 3.50651\tvalid_1's rmse: 3.19684\n",
      "[13]\ttraining's rmse: 3.48206\tvalid_1's rmse: 3.17261\n",
      "[14]\ttraining's rmse: 3.45739\tvalid_1's rmse: 3.14835\n",
      "[15]\ttraining's rmse: 3.43276\tvalid_1's rmse: 3.12407\n",
      "[16]\ttraining's rmse: 3.40764\tvalid_1's rmse: 3.0994\n",
      "[17]\ttraining's rmse: 3.3825\tvalid_1's rmse: 3.0749\n",
      "[18]\ttraining's rmse: 3.35796\tvalid_1's rmse: 3.05086\n",
      "[19]\ttraining's rmse: 3.33239\tvalid_1's rmse: 3.0261\n",
      "[20]\ttraining's rmse: 3.3074\tvalid_1's rmse: 3.00189\n",
      "[21]\ttraining's rmse: 3.28189\tvalid_1's rmse: 2.97734\n",
      "[22]\ttraining's rmse: 3.25674\tvalid_1's rmse: 2.95317\n",
      "[23]\ttraining's rmse: 3.23152\tvalid_1's rmse: 2.92903\n",
      "[24]\ttraining's rmse: 3.20548\tvalid_1's rmse: 2.90401\n",
      "[25]\ttraining's rmse: 3.17967\tvalid_1's rmse: 2.87968\n",
      "[26]\ttraining's rmse: 3.15417\tvalid_1's rmse: 2.85559\n",
      "[27]\ttraining's rmse: 3.12873\tvalid_1's rmse: 2.83153\n",
      "[28]\ttraining's rmse: 3.10322\tvalid_1's rmse: 2.80767\n",
      "[29]\ttraining's rmse: 3.07797\tvalid_1's rmse: 2.78392\n",
      "[30]\ttraining's rmse: 3.05331\tvalid_1's rmse: 2.76077\n",
      "[31]\ttraining's rmse: 3.02912\tvalid_1's rmse: 2.7382\n",
      "[32]\ttraining's rmse: 3.00418\tvalid_1's rmse: 2.71511\n",
      "[33]\ttraining's rmse: 2.97952\tvalid_1's rmse: 2.6921\n",
      "[34]\ttraining's rmse: 2.95549\tvalid_1's rmse: 2.67008\n",
      "[35]\ttraining's rmse: 2.93237\tvalid_1's rmse: 2.6487\n",
      "[36]\ttraining's rmse: 2.90951\tvalid_1's rmse: 2.6279\n",
      "[37]\ttraining's rmse: 2.88617\tvalid_1's rmse: 2.60697\n",
      "[38]\ttraining's rmse: 2.86393\tvalid_1's rmse: 2.58653\n",
      "[39]\ttraining's rmse: 2.84158\tvalid_1's rmse: 2.56636\n",
      "[40]\ttraining's rmse: 2.8196\tvalid_1's rmse: 2.54673\n",
      "[41]\ttraining's rmse: 2.79815\tvalid_1's rmse: 2.5273\n",
      "[42]\ttraining's rmse: 2.77726\tvalid_1's rmse: 2.50869\n",
      "[43]\ttraining's rmse: 2.75655\tvalid_1's rmse: 2.49016\n",
      "[44]\ttraining's rmse: 2.73684\tvalid_1's rmse: 2.47224\n",
      "[45]\ttraining's rmse: 2.71786\tvalid_1's rmse: 2.45513\n",
      "[46]\ttraining's rmse: 2.69869\tvalid_1's rmse: 2.43828\n",
      "[47]\ttraining's rmse: 2.67994\tvalid_1's rmse: 2.42197\n",
      "[48]\ttraining's rmse: 2.66213\tvalid_1's rmse: 2.40633\n",
      "[49]\ttraining's rmse: 2.64445\tvalid_1's rmse: 2.3909\n",
      "[50]\ttraining's rmse: 2.62707\tvalid_1's rmse: 2.37565\n",
      "[51]\ttraining's rmse: 2.61068\tvalid_1's rmse: 2.36089\n",
      "[52]\ttraining's rmse: 2.59455\tvalid_1's rmse: 2.34717\n",
      "[53]\ttraining's rmse: 2.57879\tvalid_1's rmse: 2.33332\n",
      "[54]\ttraining's rmse: 2.56341\tvalid_1's rmse: 2.32062\n",
      "[55]\ttraining's rmse: 2.54898\tvalid_1's rmse: 2.30839\n",
      "[56]\ttraining's rmse: 2.53489\tvalid_1's rmse: 2.29669\n",
      "[57]\ttraining's rmse: 2.52086\tvalid_1's rmse: 2.28489\n",
      "[58]\ttraining's rmse: 2.50774\tvalid_1's rmse: 2.27358\n",
      "[59]\ttraining's rmse: 2.49515\tvalid_1's rmse: 2.26255\n",
      "[60]\ttraining's rmse: 2.48248\tvalid_1's rmse: 2.25207\n",
      "[61]\ttraining's rmse: 2.47078\tvalid_1's rmse: 2.24221\n",
      "[62]\ttraining's rmse: 2.45943\tvalid_1's rmse: 2.23228\n",
      "[63]\ttraining's rmse: 2.44817\tvalid_1's rmse: 2.22255\n",
      "[64]\ttraining's rmse: 2.43747\tvalid_1's rmse: 2.21387\n",
      "[65]\ttraining's rmse: 2.42752\tvalid_1's rmse: 2.20599\n",
      "[66]\ttraining's rmse: 2.41729\tvalid_1's rmse: 2.19824\n",
      "[67]\ttraining's rmse: 2.40738\tvalid_1's rmse: 2.19043\n",
      "[68]\ttraining's rmse: 2.39836\tvalid_1's rmse: 2.18301\n",
      "[69]\ttraining's rmse: 2.38961\tvalid_1's rmse: 2.17587\n",
      "[70]\ttraining's rmse: 2.38086\tvalid_1's rmse: 2.16891\n",
      "[71]\ttraining's rmse: 2.37248\tvalid_1's rmse: 2.16219\n",
      "[72]\ttraining's rmse: 2.36449\tvalid_1's rmse: 2.15595\n",
      "[73]\ttraining's rmse: 2.35688\tvalid_1's rmse: 2.14977\n",
      "[74]\ttraining's rmse: 2.34953\tvalid_1's rmse: 2.14396\n",
      "[75]\ttraining's rmse: 2.34197\tvalid_1's rmse: 2.13842\n",
      "[76]\ttraining's rmse: 2.33533\tvalid_1's rmse: 2.1335\n",
      "[77]\ttraining's rmse: 2.3289\tvalid_1's rmse: 2.1284\n",
      "[78]\ttraining's rmse: 2.32246\tvalid_1's rmse: 2.12353\n",
      "[79]\ttraining's rmse: 2.31665\tvalid_1's rmse: 2.11952\n",
      "[80]\ttraining's rmse: 2.31131\tvalid_1's rmse: 2.11541\n",
      "[81]\ttraining's rmse: 2.30546\tvalid_1's rmse: 2.11099\n",
      "[82]\ttraining's rmse: 2.2998\tvalid_1's rmse: 2.10696\n",
      "[83]\ttraining's rmse: 2.29421\tvalid_1's rmse: 2.10337\n",
      "[84]\ttraining's rmse: 2.28907\tvalid_1's rmse: 2.09921\n",
      "[85]\ttraining's rmse: 2.28453\tvalid_1's rmse: 2.09563\n",
      "[86]\ttraining's rmse: 2.27978\tvalid_1's rmse: 2.0924\n",
      "[87]\ttraining's rmse: 2.27484\tvalid_1's rmse: 2.08912\n",
      "[88]\ttraining's rmse: 2.27034\tvalid_1's rmse: 2.08621\n",
      "[89]\ttraining's rmse: 2.26632\tvalid_1's rmse: 2.08339\n",
      "[90]\ttraining's rmse: 2.26244\tvalid_1's rmse: 2.08073\n",
      "[91]\ttraining's rmse: 2.25858\tvalid_1's rmse: 2.07822\n",
      "[92]\ttraining's rmse: 2.25494\tvalid_1's rmse: 2.07566\n",
      "[93]\ttraining's rmse: 2.25135\tvalid_1's rmse: 2.07353\n",
      "[94]\ttraining's rmse: 2.24797\tvalid_1's rmse: 2.07128\n",
      "[95]\ttraining's rmse: 2.24472\tvalid_1's rmse: 2.06904\n",
      "[96]\ttraining's rmse: 2.24156\tvalid_1's rmse: 2.06716\n",
      "[97]\ttraining's rmse: 2.23849\tvalid_1's rmse: 2.0651\n",
      "[98]\ttraining's rmse: 2.23568\tvalid_1's rmse: 2.06323\n",
      "[99]\ttraining's rmse: 2.23293\tvalid_1's rmse: 2.06115\n",
      "[100]\ttraining's rmse: 2.23027\tvalid_1's rmse: 2.0593\n",
      "[101]\ttraining's rmse: 2.22777\tvalid_1's rmse: 2.05791\n",
      "[102]\ttraining's rmse: 2.22519\tvalid_1's rmse: 2.05621\n",
      "[103]\ttraining's rmse: 2.22272\tvalid_1's rmse: 2.05456\n",
      "[104]\ttraining's rmse: 2.22043\tvalid_1's rmse: 2.05321\n",
      "[105]\ttraining's rmse: 2.21813\tvalid_1's rmse: 2.05183\n",
      "[106]\ttraining's rmse: 2.21619\tvalid_1's rmse: 2.05039\n",
      "[107]\ttraining's rmse: 2.21413\tvalid_1's rmse: 2.04838\n",
      "[108]\ttraining's rmse: 2.21209\tvalid_1's rmse: 2.04696\n",
      "[109]\ttraining's rmse: 2.20973\tvalid_1's rmse: 2.04578\n",
      "[110]\ttraining's rmse: 2.20767\tvalid_1's rmse: 2.04465\n",
      "[111]\ttraining's rmse: 2.20596\tvalid_1's rmse: 2.04346\n",
      "[112]\ttraining's rmse: 2.20449\tvalid_1's rmse: 2.04242\n",
      "[113]\ttraining's rmse: 2.2028\tvalid_1's rmse: 2.04163\n",
      "[114]\ttraining's rmse: 2.20119\tvalid_1's rmse: 2.04094\n",
      "[115]\ttraining's rmse: 2.19978\tvalid_1's rmse: 2.04017\n",
      "[116]\ttraining's rmse: 2.19844\tvalid_1's rmse: 2.03947\n",
      "[117]\ttraining's rmse: 2.19697\tvalid_1's rmse: 2.03883\n",
      "[118]\ttraining's rmse: 2.19554\tvalid_1's rmse: 2.03801\n",
      "[119]\ttraining's rmse: 2.19379\tvalid_1's rmse: 2.03745\n",
      "[120]\ttraining's rmse: 2.19243\tvalid_1's rmse: 2.03658\n",
      "[121]\ttraining's rmse: 2.19111\tvalid_1's rmse: 2.03597\n",
      "[122]\ttraining's rmse: 2.18939\tvalid_1's rmse: 2.03488\n",
      "[123]\ttraining's rmse: 2.18816\tvalid_1's rmse: 2.03444\n",
      "[124]\ttraining's rmse: 2.1867\tvalid_1's rmse: 2.03386\n",
      "[125]\ttraining's rmse: 2.18541\tvalid_1's rmse: 2.03325\n",
      "[126]\ttraining's rmse: 2.18406\tvalid_1's rmse: 2.03259\n",
      "[127]\ttraining's rmse: 2.18266\tvalid_1's rmse: 2.03173\n",
      "[128]\ttraining's rmse: 2.18136\tvalid_1's rmse: 2.03093\n",
      "[129]\ttraining's rmse: 2.17987\tvalid_1's rmse: 2.03027\n",
      "[130]\ttraining's rmse: 2.17883\tvalid_1's rmse: 2.02945\n",
      "[131]\ttraining's rmse: 2.17753\tvalid_1's rmse: 2.02894\n",
      "[132]\ttraining's rmse: 2.1766\tvalid_1's rmse: 2.02822\n",
      "[133]\ttraining's rmse: 2.17518\tvalid_1's rmse: 2.02763\n",
      "[134]\ttraining's rmse: 2.17419\tvalid_1's rmse: 2.02729\n",
      "[135]\ttraining's rmse: 2.17319\tvalid_1's rmse: 2.02701\n",
      "[136]\ttraining's rmse: 2.17236\tvalid_1's rmse: 2.02625\n",
      "[137]\ttraining's rmse: 2.17155\tvalid_1's rmse: 2.02588\n",
      "[138]\ttraining's rmse: 2.17044\tvalid_1's rmse: 2.02529\n",
      "[139]\ttraining's rmse: 2.16922\tvalid_1's rmse: 2.02501\n",
      "[140]\ttraining's rmse: 2.16832\tvalid_1's rmse: 2.02466\n",
      "[141]\ttraining's rmse: 2.16749\tvalid_1's rmse: 2.0242\n",
      "[142]\ttraining's rmse: 2.16679\tvalid_1's rmse: 2.02382\n",
      "[143]\ttraining's rmse: 2.16589\tvalid_1's rmse: 2.02343\n",
      "[144]\ttraining's rmse: 2.16522\tvalid_1's rmse: 2.02315\n",
      "[145]\ttraining's rmse: 2.16447\tvalid_1's rmse: 2.02289\n",
      "[146]\ttraining's rmse: 2.16383\tvalid_1's rmse: 2.02262\n",
      "[147]\ttraining's rmse: 2.16269\tvalid_1's rmse: 2.02194\n",
      "[148]\ttraining's rmse: 2.16226\tvalid_1's rmse: 2.02177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149]\ttraining's rmse: 2.16144\tvalid_1's rmse: 2.02084\n",
      "[150]\ttraining's rmse: 2.16047\tvalid_1's rmse: 2.02062\n",
      "[151]\ttraining's rmse: 2.15969\tvalid_1's rmse: 2.01959\n",
      "[152]\ttraining's rmse: 2.15916\tvalid_1's rmse: 2.0193\n",
      "[153]\ttraining's rmse: 2.15837\tvalid_1's rmse: 2.01909\n",
      "[154]\ttraining's rmse: 2.15768\tvalid_1's rmse: 2.01901\n",
      "[155]\ttraining's rmse: 2.15654\tvalid_1's rmse: 2.01876\n",
      "[156]\ttraining's rmse: 2.15548\tvalid_1's rmse: 2.01844\n",
      "[157]\ttraining's rmse: 2.15501\tvalid_1's rmse: 2.01838\n",
      "[158]\ttraining's rmse: 2.15415\tvalid_1's rmse: 2.01837\n",
      "[159]\ttraining's rmse: 2.15353\tvalid_1's rmse: 2.01815\n",
      "[160]\ttraining's rmse: 2.15238\tvalid_1's rmse: 2.01758\n",
      "[161]\ttraining's rmse: 2.15172\tvalid_1's rmse: 2.01722\n",
      "[162]\ttraining's rmse: 2.1509\tvalid_1's rmse: 2.01677\n",
      "[163]\ttraining's rmse: 2.15012\tvalid_1's rmse: 2.01642\n",
      "[164]\ttraining's rmse: 2.1497\tvalid_1's rmse: 2.01634\n",
      "[165]\ttraining's rmse: 2.1488\tvalid_1's rmse: 2.01479\n",
      "[166]\ttraining's rmse: 2.14818\tvalid_1's rmse: 2.0146\n",
      "[167]\ttraining's rmse: 2.1475\tvalid_1's rmse: 2.01403\n",
      "[168]\ttraining's rmse: 2.14643\tvalid_1's rmse: 2.01367\n",
      "[169]\ttraining's rmse: 2.14553\tvalid_1's rmse: 2.01334\n",
      "[170]\ttraining's rmse: 2.14488\tvalid_1's rmse: 2.01285\n",
      "[171]\ttraining's rmse: 2.14438\tvalid_1's rmse: 2.01273\n",
      "[172]\ttraining's rmse: 2.144\tvalid_1's rmse: 2.01265\n",
      "[173]\ttraining's rmse: 2.14352\tvalid_1's rmse: 2.01245\n",
      "[174]\ttraining's rmse: 2.1429\tvalid_1's rmse: 2.01212\n",
      "[175]\ttraining's rmse: 2.14262\tvalid_1's rmse: 2.01216\n",
      "[176]\ttraining's rmse: 2.14184\tvalid_1's rmse: 2.0116\n",
      "[177]\ttraining's rmse: 2.14136\tvalid_1's rmse: 2.01149\n",
      "[178]\ttraining's rmse: 2.14089\tvalid_1's rmse: 2.01146\n",
      "[179]\ttraining's rmse: 2.14025\tvalid_1's rmse: 2.01113\n",
      "[180]\ttraining's rmse: 2.13978\tvalid_1's rmse: 2.01017\n",
      "[181]\ttraining's rmse: 2.13906\tvalid_1's rmse: 2.01002\n",
      "[182]\ttraining's rmse: 2.13858\tvalid_1's rmse: 2.00993\n",
      "[183]\ttraining's rmse: 2.13803\tvalid_1's rmse: 2.00939\n",
      "[184]\ttraining's rmse: 2.13733\tvalid_1's rmse: 2.00917\n",
      "[185]\ttraining's rmse: 2.13674\tvalid_1's rmse: 2.00907\n",
      "[186]\ttraining's rmse: 2.13629\tvalid_1's rmse: 2.00907\n",
      "[187]\ttraining's rmse: 2.13582\tvalid_1's rmse: 2.00876\n",
      "[188]\ttraining's rmse: 2.13538\tvalid_1's rmse: 2.00872\n",
      "[189]\ttraining's rmse: 2.13496\tvalid_1's rmse: 2.00863\n",
      "[190]\ttraining's rmse: 2.13466\tvalid_1's rmse: 2.00838\n",
      "[191]\ttraining's rmse: 2.13411\tvalid_1's rmse: 2.00807\n",
      "[192]\ttraining's rmse: 2.13338\tvalid_1's rmse: 2.00717\n",
      "[193]\ttraining's rmse: 2.13312\tvalid_1's rmse: 2.00718\n",
      "[194]\ttraining's rmse: 2.13248\tvalid_1's rmse: 2.00709\n",
      "[195]\ttraining's rmse: 2.13217\tvalid_1's rmse: 2.00684\n",
      "[196]\ttraining's rmse: 2.13176\tvalid_1's rmse: 2.00674\n",
      "[197]\ttraining's rmse: 2.1311\tvalid_1's rmse: 2.00611\n",
      "[198]\ttraining's rmse: 2.13072\tvalid_1's rmse: 2.00602\n",
      "[199]\ttraining's rmse: 2.1303\tvalid_1's rmse: 2.00592\n",
      "[200]\ttraining's rmse: 2.12992\tvalid_1's rmse: 2.00593\n",
      "[201]\ttraining's rmse: 2.12944\tvalid_1's rmse: 2.00563\n",
      "[202]\ttraining's rmse: 2.12894\tvalid_1's rmse: 2.00551\n",
      "[203]\ttraining's rmse: 2.12878\tvalid_1's rmse: 2.0055\n",
      "[204]\ttraining's rmse: 2.12848\tvalid_1's rmse: 2.00547\n",
      "[205]\ttraining's rmse: 2.12812\tvalid_1's rmse: 2.00509\n",
      "[206]\ttraining's rmse: 2.12774\tvalid_1's rmse: 2.00502\n",
      "[207]\ttraining's rmse: 2.12745\tvalid_1's rmse: 2.00488\n",
      "[208]\ttraining's rmse: 2.12684\tvalid_1's rmse: 2.0047\n",
      "[209]\ttraining's rmse: 2.12645\tvalid_1's rmse: 2.00447\n",
      "[210]\ttraining's rmse: 2.1258\tvalid_1's rmse: 2.00417\n",
      "[211]\ttraining's rmse: 2.12515\tvalid_1's rmse: 2.0039\n",
      "[212]\ttraining's rmse: 2.12478\tvalid_1's rmse: 2.00384\n",
      "[213]\ttraining's rmse: 2.12456\tvalid_1's rmse: 2.00356\n",
      "[214]\ttraining's rmse: 2.12439\tvalid_1's rmse: 2.0035\n",
      "[215]\ttraining's rmse: 2.12404\tvalid_1's rmse: 2.00351\n",
      "[216]\ttraining's rmse: 2.1238\tvalid_1's rmse: 2.00341\n",
      "[217]\ttraining's rmse: 2.12338\tvalid_1's rmse: 2.00315\n",
      "[218]\ttraining's rmse: 2.12302\tvalid_1's rmse: 2.00314\n",
      "[219]\ttraining's rmse: 2.12262\tvalid_1's rmse: 2.00284\n",
      "[220]\ttraining's rmse: 2.12245\tvalid_1's rmse: 2.0027\n",
      "[221]\ttraining's rmse: 2.12194\tvalid_1's rmse: 2.00246\n",
      "[222]\ttraining's rmse: 2.12158\tvalid_1's rmse: 2.00197\n",
      "[223]\ttraining's rmse: 2.12136\tvalid_1's rmse: 2.00172\n",
      "[224]\ttraining's rmse: 2.12112\tvalid_1's rmse: 2.00165\n",
      "[225]\ttraining's rmse: 2.12085\tvalid_1's rmse: 2.00157\n",
      "[226]\ttraining's rmse: 2.12064\tvalid_1's rmse: 2.00155\n",
      "[227]\ttraining's rmse: 2.12046\tvalid_1's rmse: 2.00142\n",
      "[228]\ttraining's rmse: 2.12002\tvalid_1's rmse: 2.00121\n",
      "[229]\ttraining's rmse: 2.11969\tvalid_1's rmse: 2.00119\n",
      "[230]\ttraining's rmse: 2.11931\tvalid_1's rmse: 2.00098\n",
      "[231]\ttraining's rmse: 2.11891\tvalid_1's rmse: 2.00087\n",
      "[232]\ttraining's rmse: 2.11848\tvalid_1's rmse: 2.0007\n",
      "[233]\ttraining's rmse: 2.11772\tvalid_1's rmse: 2.00052\n",
      "[234]\ttraining's rmse: 2.11739\tvalid_1's rmse: 2.00052\n",
      "[235]\ttraining's rmse: 2.11692\tvalid_1's rmse: 2.00024\n",
      "[236]\ttraining's rmse: 2.1166\tvalid_1's rmse: 2\n",
      "[237]\ttraining's rmse: 2.11636\tvalid_1's rmse: 1.99992\n",
      "[238]\ttraining's rmse: 2.1162\tvalid_1's rmse: 1.99995\n",
      "[239]\ttraining's rmse: 2.11608\tvalid_1's rmse: 1.99992\n",
      "[240]\ttraining's rmse: 2.11535\tvalid_1's rmse: 1.9992\n",
      "[241]\ttraining's rmse: 2.11514\tvalid_1's rmse: 1.99919\n",
      "[242]\ttraining's rmse: 2.11476\tvalid_1's rmse: 1.99888\n",
      "[243]\ttraining's rmse: 2.1146\tvalid_1's rmse: 1.99878\n",
      "[244]\ttraining's rmse: 2.11447\tvalid_1's rmse: 1.99859\n",
      "[245]\ttraining's rmse: 2.11426\tvalid_1's rmse: 1.99855\n",
      "[246]\ttraining's rmse: 2.11402\tvalid_1's rmse: 1.99849\n",
      "[247]\ttraining's rmse: 2.11382\tvalid_1's rmse: 1.99838\n",
      "[248]\ttraining's rmse: 2.11369\tvalid_1's rmse: 1.9983\n",
      "[249]\ttraining's rmse: 2.11353\tvalid_1's rmse: 1.9983\n",
      "[250]\ttraining's rmse: 2.11322\tvalid_1's rmse: 1.99809\n",
      "[251]\ttraining's rmse: 2.11289\tvalid_1's rmse: 1.99793\n",
      "[252]\ttraining's rmse: 2.11271\tvalid_1's rmse: 1.99784\n",
      "[253]\ttraining's rmse: 2.11246\tvalid_1's rmse: 1.99781\n",
      "[254]\ttraining's rmse: 2.11224\tvalid_1's rmse: 1.99775\n",
      "[255]\ttraining's rmse: 2.11201\tvalid_1's rmse: 1.99763\n",
      "[256]\ttraining's rmse: 2.11144\tvalid_1's rmse: 1.99746\n",
      "[257]\ttraining's rmse: 2.11106\tvalid_1's rmse: 1.99736\n",
      "[258]\ttraining's rmse: 2.11077\tvalid_1's rmse: 1.99732\n",
      "[259]\ttraining's rmse: 2.11017\tvalid_1's rmse: 1.99695\n",
      "[260]\ttraining's rmse: 2.10995\tvalid_1's rmse: 1.9969\n",
      "[261]\ttraining's rmse: 2.10912\tvalid_1's rmse: 1.99676\n",
      "[262]\ttraining's rmse: 2.10875\tvalid_1's rmse: 1.99667\n",
      "[263]\ttraining's rmse: 2.10814\tvalid_1's rmse: 1.99637\n",
      "[264]\ttraining's rmse: 2.10802\tvalid_1's rmse: 1.99634\n",
      "[265]\ttraining's rmse: 2.10758\tvalid_1's rmse: 1.99631\n",
      "[266]\ttraining's rmse: 2.10696\tvalid_1's rmse: 1.9961\n",
      "[267]\ttraining's rmse: 2.10687\tvalid_1's rmse: 1.99605\n",
      "[268]\ttraining's rmse: 2.10668\tvalid_1's rmse: 1.99574\n",
      "[269]\ttraining's rmse: 2.10651\tvalid_1's rmse: 1.99568\n",
      "[270]\ttraining's rmse: 2.10647\tvalid_1's rmse: 1.99567\n",
      "[271]\ttraining's rmse: 2.10605\tvalid_1's rmse: 1.99553\n",
      "[272]\ttraining's rmse: 2.10566\tvalid_1's rmse: 1.99554\n",
      "[273]\ttraining's rmse: 2.1056\tvalid_1's rmse: 1.99553\n",
      "[274]\ttraining's rmse: 2.105\tvalid_1's rmse: 1.99476\n",
      "[275]\ttraining's rmse: 2.10447\tvalid_1's rmse: 1.99463\n",
      "[276]\ttraining's rmse: 2.10378\tvalid_1's rmse: 1.99464\n",
      "[277]\ttraining's rmse: 2.10346\tvalid_1's rmse: 1.99459\n",
      "[278]\ttraining's rmse: 2.10277\tvalid_1's rmse: 1.99452\n",
      "[279]\ttraining's rmse: 2.10248\tvalid_1's rmse: 1.99448\n",
      "[280]\ttraining's rmse: 2.10216\tvalid_1's rmse: 1.99436\n",
      "[281]\ttraining's rmse: 2.10207\tvalid_1's rmse: 1.99434\n",
      "[282]\ttraining's rmse: 2.1018\tvalid_1's rmse: 1.994\n",
      "[283]\ttraining's rmse: 2.10092\tvalid_1's rmse: 1.99367\n",
      "[284]\ttraining's rmse: 2.10083\tvalid_1's rmse: 1.99366\n",
      "[285]\ttraining's rmse: 2.10048\tvalid_1's rmse: 1.99351\n",
      "[286]\ttraining's rmse: 2.09999\tvalid_1's rmse: 1.99334\n",
      "[287]\ttraining's rmse: 2.09947\tvalid_1's rmse: 1.99292\n",
      "[288]\ttraining's rmse: 2.09893\tvalid_1's rmse: 1.99258\n",
      "[289]\ttraining's rmse: 2.09867\tvalid_1's rmse: 1.9921\n",
      "[290]\ttraining's rmse: 2.09816\tvalid_1's rmse: 1.99162\n",
      "[291]\ttraining's rmse: 2.09781\tvalid_1's rmse: 1.99145\n",
      "[292]\ttraining's rmse: 2.09734\tvalid_1's rmse: 1.99138\n",
      "[293]\ttraining's rmse: 2.09718\tvalid_1's rmse: 1.99125\n",
      "[294]\ttraining's rmse: 2.0971\tvalid_1's rmse: 1.99125\n",
      "[295]\ttraining's rmse: 2.09685\tvalid_1's rmse: 1.99114\n",
      "[296]\ttraining's rmse: 2.09655\tvalid_1's rmse: 1.99083\n",
      "[297]\ttraining's rmse: 2.09628\tvalid_1's rmse: 1.99079\n",
      "[298]\ttraining's rmse: 2.09624\tvalid_1's rmse: 1.99075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[299]\ttraining's rmse: 2.09611\tvalid_1's rmse: 1.99068\n",
      "[300]\ttraining's rmse: 2.09585\tvalid_1's rmse: 1.9906\n",
      "[301]\ttraining's rmse: 2.0952\tvalid_1's rmse: 1.99027\n",
      "[302]\ttraining's rmse: 2.09497\tvalid_1's rmse: 1.99006\n",
      "[303]\ttraining's rmse: 2.09461\tvalid_1's rmse: 1.98982\n",
      "[304]\ttraining's rmse: 2.0945\tvalid_1's rmse: 1.98986\n",
      "[305]\ttraining's rmse: 2.09393\tvalid_1's rmse: 1.9892\n",
      "[306]\ttraining's rmse: 2.09385\tvalid_1's rmse: 1.98918\n",
      "[307]\ttraining's rmse: 2.09331\tvalid_1's rmse: 1.98734\n",
      "[308]\ttraining's rmse: 2.09295\tvalid_1's rmse: 1.98715\n",
      "[309]\ttraining's rmse: 2.09291\tvalid_1's rmse: 1.98711\n",
      "[310]\ttraining's rmse: 2.09237\tvalid_1's rmse: 1.98702\n",
      "[311]\ttraining's rmse: 2.09178\tvalid_1's rmse: 1.98687\n",
      "[312]\ttraining's rmse: 2.09147\tvalid_1's rmse: 1.98675\n",
      "[313]\ttraining's rmse: 2.09126\tvalid_1's rmse: 1.98667\n",
      "[314]\ttraining's rmse: 2.09107\tvalid_1's rmse: 1.98649\n",
      "[315]\ttraining's rmse: 2.09045\tvalid_1's rmse: 1.98632\n",
      "[316]\ttraining's rmse: 2.0899\tvalid_1's rmse: 1.98614\n",
      "[317]\ttraining's rmse: 2.08985\tvalid_1's rmse: 1.98612\n",
      "[318]\ttraining's rmse: 2.08953\tvalid_1's rmse: 1.98605\n",
      "[319]\ttraining's rmse: 2.08926\tvalid_1's rmse: 1.98591\n",
      "[320]\ttraining's rmse: 2.08913\tvalid_1's rmse: 1.98589\n",
      "[321]\ttraining's rmse: 2.08847\tvalid_1's rmse: 1.98574\n",
      "[322]\ttraining's rmse: 2.08796\tvalid_1's rmse: 1.98536\n",
      "[323]\ttraining's rmse: 2.08772\tvalid_1's rmse: 1.98531\n",
      "[324]\ttraining's rmse: 2.08767\tvalid_1's rmse: 1.98529\n",
      "[325]\ttraining's rmse: 2.08762\tvalid_1's rmse: 1.98529\n",
      "[326]\ttraining's rmse: 2.08724\tvalid_1's rmse: 1.98526\n",
      "[327]\ttraining's rmse: 2.08666\tvalid_1's rmse: 1.98466\n",
      "[328]\ttraining's rmse: 2.08661\tvalid_1's rmse: 1.98464\n",
      "[329]\ttraining's rmse: 2.08614\tvalid_1's rmse: 1.98464\n",
      "[330]\ttraining's rmse: 2.08582\tvalid_1's rmse: 1.98423\n",
      "[331]\ttraining's rmse: 2.08578\tvalid_1's rmse: 1.9842\n",
      "[332]\ttraining's rmse: 2.08571\tvalid_1's rmse: 1.98418\n",
      "[333]\ttraining's rmse: 2.08527\tvalid_1's rmse: 1.98348\n",
      "[334]\ttraining's rmse: 2.08512\tvalid_1's rmse: 1.98345\n",
      "[335]\ttraining's rmse: 2.0851\tvalid_1's rmse: 1.98344\n",
      "[336]\ttraining's rmse: 2.08503\tvalid_1's rmse: 1.98342\n",
      "[337]\ttraining's rmse: 2.0849\tvalid_1's rmse: 1.98331\n",
      "[338]\ttraining's rmse: 2.08458\tvalid_1's rmse: 1.98323\n",
      "[339]\ttraining's rmse: 2.08413\tvalid_1's rmse: 1.98289\n",
      "[340]\ttraining's rmse: 2.08379\tvalid_1's rmse: 1.98273\n",
      "[341]\ttraining's rmse: 2.08339\tvalid_1's rmse: 1.98259\n",
      "[342]\ttraining's rmse: 2.0833\tvalid_1's rmse: 1.98258\n",
      "[343]\ttraining's rmse: 2.08311\tvalid_1's rmse: 1.98252\n",
      "[344]\ttraining's rmse: 2.08262\tvalid_1's rmse: 1.98188\n",
      "[345]\ttraining's rmse: 2.08241\tvalid_1's rmse: 1.98187\n",
      "[346]\ttraining's rmse: 2.08169\tvalid_1's rmse: 1.98142\n",
      "[347]\ttraining's rmse: 2.08165\tvalid_1's rmse: 1.9814\n",
      "[348]\ttraining's rmse: 2.08162\tvalid_1's rmse: 1.98139\n",
      "[349]\ttraining's rmse: 2.08127\tvalid_1's rmse: 1.98125\n",
      "[350]\ttraining's rmse: 2.08073\tvalid_1's rmse: 1.98117\n",
      "[351]\ttraining's rmse: 2.08031\tvalid_1's rmse: 1.98097\n",
      "[352]\ttraining's rmse: 2.08013\tvalid_1's rmse: 1.9809\n",
      "[353]\ttraining's rmse: 2.07974\tvalid_1's rmse: 1.98067\n",
      "[354]\ttraining's rmse: 2.07926\tvalid_1's rmse: 1.98022\n",
      "[355]\ttraining's rmse: 2.07921\tvalid_1's rmse: 1.9802\n",
      "[356]\ttraining's rmse: 2.07901\tvalid_1's rmse: 1.97959\n",
      "[357]\ttraining's rmse: 2.07858\tvalid_1's rmse: 1.979\n",
      "[358]\ttraining's rmse: 2.07821\tvalid_1's rmse: 1.9789\n",
      "[359]\ttraining's rmse: 2.07818\tvalid_1's rmse: 1.97889\n",
      "[360]\ttraining's rmse: 2.07802\tvalid_1's rmse: 1.97886\n",
      "[361]\ttraining's rmse: 2.07761\tvalid_1's rmse: 1.9784\n",
      "[362]\ttraining's rmse: 2.07754\tvalid_1's rmse: 1.97839\n",
      "[363]\ttraining's rmse: 2.07708\tvalid_1's rmse: 1.97816\n",
      "[364]\ttraining's rmse: 2.07705\tvalid_1's rmse: 1.97815\n",
      "[365]\ttraining's rmse: 2.07634\tvalid_1's rmse: 1.97775\n",
      "[366]\ttraining's rmse: 2.07596\tvalid_1's rmse: 1.97741\n",
      "[367]\ttraining's rmse: 2.07574\tvalid_1's rmse: 1.97742\n",
      "[368]\ttraining's rmse: 2.07554\tvalid_1's rmse: 1.97736\n",
      "[369]\ttraining's rmse: 2.07514\tvalid_1's rmse: 1.97701\n",
      "[370]\ttraining's rmse: 2.07475\tvalid_1's rmse: 1.97643\n",
      "[371]\ttraining's rmse: 2.07448\tvalid_1's rmse: 1.97635\n",
      "[372]\ttraining's rmse: 2.07444\tvalid_1's rmse: 1.97633\n",
      "[373]\ttraining's rmse: 2.07417\tvalid_1's rmse: 1.97619\n",
      "[374]\ttraining's rmse: 2.07414\tvalid_1's rmse: 1.97618\n",
      "[375]\ttraining's rmse: 2.07361\tvalid_1's rmse: 1.97557\n",
      "[376]\ttraining's rmse: 2.07341\tvalid_1's rmse: 1.97555\n",
      "[377]\ttraining's rmse: 2.07276\tvalid_1's rmse: 1.97549\n",
      "[378]\ttraining's rmse: 2.07229\tvalid_1's rmse: 1.97514\n",
      "[379]\ttraining's rmse: 2.07222\tvalid_1's rmse: 1.97512\n",
      "[380]\ttraining's rmse: 2.07192\tvalid_1's rmse: 1.97494\n",
      "[381]\ttraining's rmse: 2.07123\tvalid_1's rmse: 1.97459\n",
      "[382]\ttraining's rmse: 2.07078\tvalid_1's rmse: 1.97413\n",
      "[383]\ttraining's rmse: 2.07056\tvalid_1's rmse: 1.97402\n",
      "[384]\ttraining's rmse: 2.07026\tvalid_1's rmse: 1.97354\n",
      "[385]\ttraining's rmse: 2.07018\tvalid_1's rmse: 1.97351\n",
      "[386]\ttraining's rmse: 2.07011\tvalid_1's rmse: 1.9735\n",
      "[387]\ttraining's rmse: 2.06967\tvalid_1's rmse: 1.97331\n",
      "[388]\ttraining's rmse: 2.06961\tvalid_1's rmse: 1.9733\n",
      "[389]\ttraining's rmse: 2.06911\tvalid_1's rmse: 1.97313\n",
      "[390]\ttraining's rmse: 2.0684\tvalid_1's rmse: 1.97297\n",
      "[391]\ttraining's rmse: 2.06792\tvalid_1's rmse: 1.97276\n",
      "[392]\ttraining's rmse: 2.06756\tvalid_1's rmse: 1.97274\n",
      "[393]\ttraining's rmse: 2.06709\tvalid_1's rmse: 1.97249\n",
      "[394]\ttraining's rmse: 2.06707\tvalid_1's rmse: 1.97248\n",
      "[395]\ttraining's rmse: 2.06633\tvalid_1's rmse: 1.97232\n",
      "[396]\ttraining's rmse: 2.06628\tvalid_1's rmse: 1.97231\n",
      "[397]\ttraining's rmse: 2.06582\tvalid_1's rmse: 1.97212\n",
      "[398]\ttraining's rmse: 2.06579\tvalid_1's rmse: 1.97211\n",
      "[399]\ttraining's rmse: 2.06545\tvalid_1's rmse: 1.9721\n",
      "[400]\ttraining's rmse: 2.06492\tvalid_1's rmse: 1.97185\n",
      "[401]\ttraining's rmse: 2.06443\tvalid_1's rmse: 1.9713\n",
      "[402]\ttraining's rmse: 2.06417\tvalid_1's rmse: 1.97102\n",
      "[403]\ttraining's rmse: 2.06392\tvalid_1's rmse: 1.97087\n",
      "[404]\ttraining's rmse: 2.06368\tvalid_1's rmse: 1.97078\n",
      "[405]\ttraining's rmse: 2.06341\tvalid_1's rmse: 1.97067\n",
      "[406]\ttraining's rmse: 2.06312\tvalid_1's rmse: 1.97047\n",
      "[407]\ttraining's rmse: 2.06281\tvalid_1's rmse: 1.97036\n",
      "[408]\ttraining's rmse: 2.06244\tvalid_1's rmse: 1.97033\n",
      "[409]\ttraining's rmse: 2.06241\tvalid_1's rmse: 1.97031\n",
      "[410]\ttraining's rmse: 2.06224\tvalid_1's rmse: 1.97018\n",
      "[411]\ttraining's rmse: 2.06174\tvalid_1's rmse: 1.96991\n",
      "[412]\ttraining's rmse: 2.06141\tvalid_1's rmse: 1.96976\n",
      "[413]\ttraining's rmse: 2.06078\tvalid_1's rmse: 1.96962\n",
      "[414]\ttraining's rmse: 2.06054\tvalid_1's rmse: 1.96946\n",
      "[415]\ttraining's rmse: 2.06037\tvalid_1's rmse: 1.9692\n",
      "[416]\ttraining's rmse: 2.06\tvalid_1's rmse: 1.96904\n",
      "[417]\ttraining's rmse: 2.05974\tvalid_1's rmse: 1.9689\n",
      "[418]\ttraining's rmse: 2.05946\tvalid_1's rmse: 1.96885\n",
      "[419]\ttraining's rmse: 2.05894\tvalid_1's rmse: 1.96812\n",
      "[420]\ttraining's rmse: 2.05892\tvalid_1's rmse: 1.96811\n",
      "[421]\ttraining's rmse: 2.05852\tvalid_1's rmse: 1.96791\n",
      "[422]\ttraining's rmse: 2.05792\tvalid_1's rmse: 1.9676\n",
      "[423]\ttraining's rmse: 2.05754\tvalid_1's rmse: 1.96721\n",
      "[424]\ttraining's rmse: 2.05704\tvalid_1's rmse: 1.96664\n",
      "[425]\ttraining's rmse: 2.0567\tvalid_1's rmse: 1.96654\n",
      "[426]\ttraining's rmse: 2.0563\tvalid_1's rmse: 1.96627\n",
      "[427]\ttraining's rmse: 2.05598\tvalid_1's rmse: 1.96608\n",
      "[428]\ttraining's rmse: 2.05536\tvalid_1's rmse: 1.96569\n",
      "[429]\ttraining's rmse: 2.05504\tvalid_1's rmse: 1.96542\n",
      "[430]\ttraining's rmse: 2.05457\tvalid_1's rmse: 1.96499\n",
      "[431]\ttraining's rmse: 2.05443\tvalid_1's rmse: 1.96499\n",
      "[432]\ttraining's rmse: 2.05396\tvalid_1's rmse: 1.96461\n",
      "[433]\ttraining's rmse: 2.0537\tvalid_1's rmse: 1.96434\n",
      "[434]\ttraining's rmse: 2.05361\tvalid_1's rmse: 1.96425\n",
      "[435]\ttraining's rmse: 2.05293\tvalid_1's rmse: 1.96367\n",
      "[436]\ttraining's rmse: 2.05264\tvalid_1's rmse: 1.96356\n",
      "[437]\ttraining's rmse: 2.05263\tvalid_1's rmse: 1.96355\n",
      "[438]\ttraining's rmse: 2.05229\tvalid_1's rmse: 1.96319\n",
      "[439]\ttraining's rmse: 2.05225\tvalid_1's rmse: 1.96319\n",
      "[440]\ttraining's rmse: 2.05184\tvalid_1's rmse: 1.96308\n",
      "[441]\ttraining's rmse: 2.05137\tvalid_1's rmse: 1.96308\n",
      "[442]\ttraining's rmse: 2.05102\tvalid_1's rmse: 1.96264\n",
      "[443]\ttraining's rmse: 2.05083\tvalid_1's rmse: 1.96261\n",
      "[444]\ttraining's rmse: 2.05058\tvalid_1's rmse: 1.96239\n",
      "[445]\ttraining's rmse: 2.05036\tvalid_1's rmse: 1.96205\n",
      "[446]\ttraining's rmse: 2.04975\tvalid_1's rmse: 1.96198\n",
      "[447]\ttraining's rmse: 2.04955\tvalid_1's rmse: 1.9618\n",
      "[448]\ttraining's rmse: 2.04916\tvalid_1's rmse: 1.96166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[449]\ttraining's rmse: 2.04878\tvalid_1's rmse: 1.96153\n",
      "[450]\ttraining's rmse: 2.04854\tvalid_1's rmse: 1.96141\n",
      "[451]\ttraining's rmse: 2.04847\tvalid_1's rmse: 1.9614\n",
      "[452]\ttraining's rmse: 2.04781\tvalid_1's rmse: 1.96116\n",
      "[453]\ttraining's rmse: 2.04708\tvalid_1's rmse: 1.96083\n",
      "[454]\ttraining's rmse: 2.04706\tvalid_1's rmse: 1.96079\n",
      "[455]\ttraining's rmse: 2.04659\tvalid_1's rmse: 1.96045\n",
      "[456]\ttraining's rmse: 2.04622\tvalid_1's rmse: 1.96019\n",
      "[457]\ttraining's rmse: 2.04585\tvalid_1's rmse: 1.9598\n",
      "[458]\ttraining's rmse: 2.04567\tvalid_1's rmse: 1.95973\n",
      "[459]\ttraining's rmse: 2.04474\tvalid_1's rmse: 1.95952\n",
      "[460]\ttraining's rmse: 2.0443\tvalid_1's rmse: 1.95927\n",
      "[461]\ttraining's rmse: 2.04394\tvalid_1's rmse: 1.95913\n",
      "[462]\ttraining's rmse: 2.04376\tvalid_1's rmse: 1.95805\n",
      "[463]\ttraining's rmse: 2.04367\tvalid_1's rmse: 1.95803\n",
      "[464]\ttraining's rmse: 2.04364\tvalid_1's rmse: 1.95801\n",
      "[465]\ttraining's rmse: 2.04316\tvalid_1's rmse: 1.95768\n",
      "[466]\ttraining's rmse: 2.04244\tvalid_1's rmse: 1.95723\n",
      "[467]\ttraining's rmse: 2.04206\tvalid_1's rmse: 1.95695\n",
      "[468]\ttraining's rmse: 2.04134\tvalid_1's rmse: 1.95682\n",
      "[469]\ttraining's rmse: 2.04102\tvalid_1's rmse: 1.95656\n",
      "[470]\ttraining's rmse: 2.04081\tvalid_1's rmse: 1.95639\n",
      "[471]\ttraining's rmse: 2.0406\tvalid_1's rmse: 1.95594\n",
      "[472]\ttraining's rmse: 2.04041\tvalid_1's rmse: 1.95567\n",
      "[473]\ttraining's rmse: 2.04007\tvalid_1's rmse: 1.95529\n",
      "[474]\ttraining's rmse: 2.03921\tvalid_1's rmse: 1.95522\n",
      "[475]\ttraining's rmse: 2.03893\tvalid_1's rmse: 1.95488\n",
      "[476]\ttraining's rmse: 2.03875\tvalid_1's rmse: 1.95475\n",
      "[477]\ttraining's rmse: 2.03863\tvalid_1's rmse: 1.95474\n",
      "[478]\ttraining's rmse: 2.03862\tvalid_1's rmse: 1.95472\n",
      "[479]\ttraining's rmse: 2.03849\tvalid_1's rmse: 1.95466\n",
      "[480]\ttraining's rmse: 2.03818\tvalid_1's rmse: 1.95439\n",
      "[481]\ttraining's rmse: 2.03787\tvalid_1's rmse: 1.95418\n",
      "[482]\ttraining's rmse: 2.03749\tvalid_1's rmse: 1.95386\n",
      "[483]\ttraining's rmse: 2.03746\tvalid_1's rmse: 1.95382\n",
      "[484]\ttraining's rmse: 2.03738\tvalid_1's rmse: 1.9538\n",
      "[485]\ttraining's rmse: 2.03712\tvalid_1's rmse: 1.95353\n",
      "[486]\ttraining's rmse: 2.03703\tvalid_1's rmse: 1.95339\n",
      "[487]\ttraining's rmse: 2.03699\tvalid_1's rmse: 1.95338\n",
      "[488]\ttraining's rmse: 2.03677\tvalid_1's rmse: 1.95337\n",
      "[489]\ttraining's rmse: 2.03676\tvalid_1's rmse: 1.95336\n",
      "[490]\ttraining's rmse: 2.03651\tvalid_1's rmse: 1.95327\n",
      "[491]\ttraining's rmse: 2.03614\tvalid_1's rmse: 1.9528\n",
      "[492]\ttraining's rmse: 2.03595\tvalid_1's rmse: 1.95276\n",
      "[493]\ttraining's rmse: 2.0357\tvalid_1's rmse: 1.95274\n",
      "[494]\ttraining's rmse: 2.03552\tvalid_1's rmse: 1.95274\n",
      "[495]\ttraining's rmse: 2.03552\tvalid_1's rmse: 1.95274\n",
      "[496]\ttraining's rmse: 2.03525\tvalid_1's rmse: 1.95252\n",
      "[497]\ttraining's rmse: 2.03444\tvalid_1's rmse: 1.95231\n",
      "[498]\ttraining's rmse: 2.03435\tvalid_1's rmse: 1.95228\n",
      "[499]\ttraining's rmse: 2.03397\tvalid_1's rmse: 1.95198\n",
      "[500]\ttraining's rmse: 2.03357\tvalid_1's rmse: 1.95179\n",
      "[501]\ttraining's rmse: 2.03337\tvalid_1's rmse: 1.95177\n",
      "[502]\ttraining's rmse: 2.03335\tvalid_1's rmse: 1.95176\n",
      "[503]\ttraining's rmse: 2.0331\tvalid_1's rmse: 1.95155\n",
      "[504]\ttraining's rmse: 2.03273\tvalid_1's rmse: 1.95129\n",
      "[505]\ttraining's rmse: 2.03244\tvalid_1's rmse: 1.95107\n",
      "[506]\ttraining's rmse: 2.03207\tvalid_1's rmse: 1.95093\n",
      "[507]\ttraining's rmse: 2.03149\tvalid_1's rmse: 1.95082\n",
      "[508]\ttraining's rmse: 2.03116\tvalid_1's rmse: 1.95042\n",
      "[509]\ttraining's rmse: 2.031\tvalid_1's rmse: 1.95025\n",
      "[510]\ttraining's rmse: 2.03044\tvalid_1's rmse: 1.95012\n",
      "[511]\ttraining's rmse: 2.02981\tvalid_1's rmse: 1.94957\n",
      "[512]\ttraining's rmse: 2.02946\tvalid_1's rmse: 1.94944\n",
      "[513]\ttraining's rmse: 2.02911\tvalid_1's rmse: 1.94881\n",
      "[514]\ttraining's rmse: 2.02906\tvalid_1's rmse: 1.94881\n",
      "[515]\ttraining's rmse: 2.02905\tvalid_1's rmse: 1.9488\n",
      "[516]\ttraining's rmse: 2.02886\tvalid_1's rmse: 1.94877\n",
      "[517]\ttraining's rmse: 2.02818\tvalid_1's rmse: 1.94838\n",
      "[518]\ttraining's rmse: 2.02795\tvalid_1's rmse: 1.94795\n",
      "[519]\ttraining's rmse: 2.02771\tvalid_1's rmse: 1.9478\n",
      "[520]\ttraining's rmse: 2.0272\tvalid_1's rmse: 1.94759\n",
      "[521]\ttraining's rmse: 2.02699\tvalid_1's rmse: 1.94742\n",
      "[522]\ttraining's rmse: 2.02688\tvalid_1's rmse: 1.94735\n",
      "[523]\ttraining's rmse: 2.02678\tvalid_1's rmse: 1.94727\n",
      "[524]\ttraining's rmse: 2.0262\tvalid_1's rmse: 1.94716\n",
      "[525]\ttraining's rmse: 2.02546\tvalid_1's rmse: 1.94675\n",
      "[526]\ttraining's rmse: 2.02513\tvalid_1's rmse: 1.94662\n",
      "[527]\ttraining's rmse: 2.02512\tvalid_1's rmse: 1.94661\n",
      "[528]\ttraining's rmse: 2.02509\tvalid_1's rmse: 1.94658\n",
      "[529]\ttraining's rmse: 2.02508\tvalid_1's rmse: 1.94658\n",
      "[530]\ttraining's rmse: 2.02507\tvalid_1's rmse: 1.94657\n",
      "[531]\ttraining's rmse: 2.02474\tvalid_1's rmse: 1.94626\n",
      "[532]\ttraining's rmse: 2.0244\tvalid_1's rmse: 1.94579\n",
      "[533]\ttraining's rmse: 2.02422\tvalid_1's rmse: 1.94564\n",
      "[534]\ttraining's rmse: 2.02376\tvalid_1's rmse: 1.9453\n",
      "[535]\ttraining's rmse: 2.02359\tvalid_1's rmse: 1.94524\n",
      "[536]\ttraining's rmse: 2.02343\tvalid_1's rmse: 1.94483\n",
      "[537]\ttraining's rmse: 2.02337\tvalid_1's rmse: 1.94478\n",
      "[538]\ttraining's rmse: 2.02315\tvalid_1's rmse: 1.94468\n",
      "[539]\ttraining's rmse: 2.023\tvalid_1's rmse: 1.94457\n",
      "[540]\ttraining's rmse: 2.02263\tvalid_1's rmse: 1.94425\n",
      "[541]\ttraining's rmse: 2.02245\tvalid_1's rmse: 1.94419\n",
      "[542]\ttraining's rmse: 2.02244\tvalid_1's rmse: 1.94416\n",
      "[543]\ttraining's rmse: 2.02218\tvalid_1's rmse: 1.94388\n",
      "[544]\ttraining's rmse: 2.02197\tvalid_1's rmse: 1.9438\n",
      "[545]\ttraining's rmse: 2.02192\tvalid_1's rmse: 1.9438\n",
      "[546]\ttraining's rmse: 2.02175\tvalid_1's rmse: 1.94371\n",
      "[547]\ttraining's rmse: 2.02162\tvalid_1's rmse: 1.94373\n",
      "[548]\ttraining's rmse: 2.02161\tvalid_1's rmse: 1.94373\n",
      "[549]\ttraining's rmse: 2.02133\tvalid_1's rmse: 1.94322\n",
      "[550]\ttraining's rmse: 2.02116\tvalid_1's rmse: 1.9432\n",
      "[551]\ttraining's rmse: 2.02044\tvalid_1's rmse: 1.94258\n",
      "[552]\ttraining's rmse: 2.01981\tvalid_1's rmse: 1.94227\n",
      "[553]\ttraining's rmse: 2.01971\tvalid_1's rmse: 1.94221\n",
      "[554]\ttraining's rmse: 2.01969\tvalid_1's rmse: 1.94218\n",
      "[555]\ttraining's rmse: 2.01967\tvalid_1's rmse: 1.94217\n",
      "[556]\ttraining's rmse: 2.01934\tvalid_1's rmse: 1.94182\n",
      "[557]\ttraining's rmse: 2.01917\tvalid_1's rmse: 1.94165\n",
      "[558]\ttraining's rmse: 2.01857\tvalid_1's rmse: 1.94153\n",
      "[559]\ttraining's rmse: 2.01821\tvalid_1's rmse: 1.94114\n",
      "[560]\ttraining's rmse: 2.0182\tvalid_1's rmse: 1.94113\n",
      "[561]\ttraining's rmse: 2.01793\tvalid_1's rmse: 1.94096\n",
      "[562]\ttraining's rmse: 2.0173\tvalid_1's rmse: 1.94092\n",
      "[563]\ttraining's rmse: 2.01681\tvalid_1's rmse: 1.94031\n",
      "[564]\ttraining's rmse: 2.01675\tvalid_1's rmse: 1.94027\n",
      "[565]\ttraining's rmse: 2.01655\tvalid_1's rmse: 1.94025\n",
      "[566]\ttraining's rmse: 2.01649\tvalid_1's rmse: 1.94023\n",
      "[567]\ttraining's rmse: 2.0163\tvalid_1's rmse: 1.94003\n",
      "[568]\ttraining's rmse: 2.01608\tvalid_1's rmse: 1.93987\n",
      "[569]\ttraining's rmse: 2.01587\tvalid_1's rmse: 1.93985\n",
      "[570]\ttraining's rmse: 2.01516\tvalid_1's rmse: 1.93969\n",
      "[571]\ttraining's rmse: 2.01505\tvalid_1's rmse: 1.93959\n",
      "[572]\ttraining's rmse: 2.01491\tvalid_1's rmse: 1.93958\n",
      "[573]\ttraining's rmse: 2.01459\tvalid_1's rmse: 1.9392\n",
      "[574]\ttraining's rmse: 2.01444\tvalid_1's rmse: 1.9392\n",
      "[575]\ttraining's rmse: 2.01386\tvalid_1's rmse: 1.93864\n",
      "[576]\ttraining's rmse: 2.0138\tvalid_1's rmse: 1.93863\n",
      "[577]\ttraining's rmse: 2.01377\tvalid_1's rmse: 1.93862\n",
      "[578]\ttraining's rmse: 2.0135\tvalid_1's rmse: 1.9384\n",
      "[579]\ttraining's rmse: 2.01342\tvalid_1's rmse: 1.93838\n",
      "[580]\ttraining's rmse: 2.01305\tvalid_1's rmse: 1.9382\n",
      "[581]\ttraining's rmse: 2.01303\tvalid_1's rmse: 1.93819\n",
      "[582]\ttraining's rmse: 2.0126\tvalid_1's rmse: 1.93801\n",
      "[583]\ttraining's rmse: 2.01243\tvalid_1's rmse: 1.93779\n",
      "[584]\ttraining's rmse: 2.01212\tvalid_1's rmse: 1.93745\n",
      "[585]\ttraining's rmse: 2.01181\tvalid_1's rmse: 1.93707\n",
      "[586]\ttraining's rmse: 2.01117\tvalid_1's rmse: 1.93648\n",
      "[587]\ttraining's rmse: 2.01101\tvalid_1's rmse: 1.93635\n",
      "[588]\ttraining's rmse: 2.01066\tvalid_1's rmse: 1.93607\n",
      "[589]\ttraining's rmse: 2.01011\tvalid_1's rmse: 1.93571\n",
      "[590]\ttraining's rmse: 2.01008\tvalid_1's rmse: 1.93571\n",
      "[591]\ttraining's rmse: 2.00996\tvalid_1's rmse: 1.93566\n",
      "[592]\ttraining's rmse: 2.00962\tvalid_1's rmse: 1.93549\n",
      "[593]\ttraining's rmse: 2.00958\tvalid_1's rmse: 1.93547\n",
      "[594]\ttraining's rmse: 2.00934\tvalid_1's rmse: 1.93535\n",
      "[595]\ttraining's rmse: 2.00929\tvalid_1's rmse: 1.93534\n",
      "[596]\ttraining's rmse: 2.00927\tvalid_1's rmse: 1.93533\n",
      "[597]\ttraining's rmse: 2.00926\tvalid_1's rmse: 1.93532\n",
      "[598]\ttraining's rmse: 2.00904\tvalid_1's rmse: 1.93528\n",
      "[599]\ttraining's rmse: 2.00888\tvalid_1's rmse: 1.93511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's rmse: 2.00857\tvalid_1's rmse: 1.93496\n",
      "[601]\ttraining's rmse: 2.00819\tvalid_1's rmse: 1.93452\n",
      "[602]\ttraining's rmse: 2.00738\tvalid_1's rmse: 1.93427\n",
      "[603]\ttraining's rmse: 2.00706\tvalid_1's rmse: 1.93411\n",
      "[604]\ttraining's rmse: 2.00678\tvalid_1's rmse: 1.93401\n",
      "[605]\ttraining's rmse: 2.00664\tvalid_1's rmse: 1.93383\n",
      "[606]\ttraining's rmse: 2.00662\tvalid_1's rmse: 1.93382\n",
      "[607]\ttraining's rmse: 2.00634\tvalid_1's rmse: 1.9338\n",
      "[608]\ttraining's rmse: 2.00615\tvalid_1's rmse: 1.93376\n",
      "[609]\ttraining's rmse: 2.00598\tvalid_1's rmse: 1.93362\n",
      "[610]\ttraining's rmse: 2.00596\tvalid_1's rmse: 1.93361\n",
      "[611]\ttraining's rmse: 2.00574\tvalid_1's rmse: 1.93326\n",
      "[612]\ttraining's rmse: 2.00562\tvalid_1's rmse: 1.93297\n",
      "[613]\ttraining's rmse: 2.00531\tvalid_1's rmse: 1.93257\n",
      "[614]\ttraining's rmse: 2.00522\tvalid_1's rmse: 1.93256\n",
      "[615]\ttraining's rmse: 2.00503\tvalid_1's rmse: 1.93218\n",
      "[616]\ttraining's rmse: 2.00472\tvalid_1's rmse: 1.93201\n",
      "[617]\ttraining's rmse: 2.00387\tvalid_1's rmse: 1.93072\n",
      "[618]\ttraining's rmse: 2.00349\tvalid_1's rmse: 1.93031\n",
      "[619]\ttraining's rmse: 2.00327\tvalid_1's rmse: 1.93007\n",
      "[620]\ttraining's rmse: 2.00304\tvalid_1's rmse: 1.92987\n",
      "[621]\ttraining's rmse: 2.00302\tvalid_1's rmse: 1.92983\n",
      "[622]\ttraining's rmse: 2.00243\tvalid_1's rmse: 1.92941\n",
      "[623]\ttraining's rmse: 2.00231\tvalid_1's rmse: 1.92938\n",
      "[624]\ttraining's rmse: 2.00228\tvalid_1's rmse: 1.92938\n",
      "[625]\ttraining's rmse: 2.00213\tvalid_1's rmse: 1.9293\n",
      "[626]\ttraining's rmse: 2.00197\tvalid_1's rmse: 1.9293\n",
      "[627]\ttraining's rmse: 2.00171\tvalid_1's rmse: 1.92923\n",
      "[628]\ttraining's rmse: 2.00108\tvalid_1's rmse: 1.92853\n",
      "[629]\ttraining's rmse: 2.00082\tvalid_1's rmse: 1.92838\n",
      "[630]\ttraining's rmse: 2.00065\tvalid_1's rmse: 1.92804\n",
      "[631]\ttraining's rmse: 2.00051\tvalid_1's rmse: 1.92796\n",
      "[632]\ttraining's rmse: 2.00044\tvalid_1's rmse: 1.92784\n",
      "[633]\ttraining's rmse: 2.00042\tvalid_1's rmse: 1.9278\n",
      "[634]\ttraining's rmse: 2.0004\tvalid_1's rmse: 1.92777\n",
      "[635]\ttraining's rmse: 2.00012\tvalid_1's rmse: 1.92743\n",
      "[636]\ttraining's rmse: 1.99989\tvalid_1's rmse: 1.92719\n",
      "[637]\ttraining's rmse: 1.99934\tvalid_1's rmse: 1.927\n",
      "[638]\ttraining's rmse: 1.99919\tvalid_1's rmse: 1.92688\n",
      "[639]\ttraining's rmse: 1.99888\tvalid_1's rmse: 1.9266\n",
      "[640]\ttraining's rmse: 1.99867\tvalid_1's rmse: 1.92656\n",
      "[641]\ttraining's rmse: 1.99837\tvalid_1's rmse: 1.92655\n",
      "[642]\ttraining's rmse: 1.998\tvalid_1's rmse: 1.9266\n",
      "[643]\ttraining's rmse: 1.99766\tvalid_1's rmse: 1.92604\n",
      "[644]\ttraining's rmse: 1.99736\tvalid_1's rmse: 1.92579\n",
      "[645]\ttraining's rmse: 1.99734\tvalid_1's rmse: 1.92578\n",
      "[646]\ttraining's rmse: 1.99708\tvalid_1's rmse: 1.92564\n",
      "[647]\ttraining's rmse: 1.99696\tvalid_1's rmse: 1.92555\n",
      "[648]\ttraining's rmse: 1.99694\tvalid_1's rmse: 1.92555\n",
      "[649]\ttraining's rmse: 1.99664\tvalid_1's rmse: 1.9254\n",
      "[650]\ttraining's rmse: 1.99644\tvalid_1's rmse: 1.9253\n",
      "[651]\ttraining's rmse: 1.99637\tvalid_1's rmse: 1.92528\n",
      "[652]\ttraining's rmse: 1.99609\tvalid_1's rmse: 1.92507\n",
      "[653]\ttraining's rmse: 1.99598\tvalid_1's rmse: 1.92503\n",
      "[654]\ttraining's rmse: 1.99572\tvalid_1's rmse: 1.92497\n",
      "[655]\ttraining's rmse: 1.9955\tvalid_1's rmse: 1.92489\n",
      "[656]\ttraining's rmse: 1.99532\tvalid_1's rmse: 1.92471\n",
      "[657]\ttraining's rmse: 1.99463\tvalid_1's rmse: 1.92437\n",
      "[658]\ttraining's rmse: 1.99392\tvalid_1's rmse: 1.92401\n",
      "[659]\ttraining's rmse: 1.99344\tvalid_1's rmse: 1.92338\n",
      "[660]\ttraining's rmse: 1.99321\tvalid_1's rmse: 1.92322\n",
      "[661]\ttraining's rmse: 1.99317\tvalid_1's rmse: 1.92321\n",
      "[662]\ttraining's rmse: 1.99304\tvalid_1's rmse: 1.92319\n",
      "[663]\ttraining's rmse: 1.99301\tvalid_1's rmse: 1.92319\n",
      "[664]\ttraining's rmse: 1.99267\tvalid_1's rmse: 1.92309\n",
      "[665]\ttraining's rmse: 1.9926\tvalid_1's rmse: 1.92306\n",
      "[666]\ttraining's rmse: 1.99259\tvalid_1's rmse: 1.92304\n",
      "[667]\ttraining's rmse: 1.99212\tvalid_1's rmse: 1.92257\n",
      "[668]\ttraining's rmse: 1.99208\tvalid_1's rmse: 1.92255\n",
      "[669]\ttraining's rmse: 1.99178\tvalid_1's rmse: 1.92215\n",
      "[670]\ttraining's rmse: 1.99153\tvalid_1's rmse: 1.92176\n",
      "[671]\ttraining's rmse: 1.99141\tvalid_1's rmse: 1.92169\n",
      "[672]\ttraining's rmse: 1.99129\tvalid_1's rmse: 1.92158\n",
      "[673]\ttraining's rmse: 1.991\tvalid_1's rmse: 1.9215\n",
      "[674]\ttraining's rmse: 1.99072\tvalid_1's rmse: 1.9214\n",
      "[675]\ttraining's rmse: 1.99066\tvalid_1's rmse: 1.9214\n",
      "[676]\ttraining's rmse: 1.99009\tvalid_1's rmse: 1.92122\n",
      "[677]\ttraining's rmse: 1.98992\tvalid_1's rmse: 1.92098\n",
      "[678]\ttraining's rmse: 1.98962\tvalid_1's rmse: 1.92051\n",
      "[679]\ttraining's rmse: 1.98934\tvalid_1's rmse: 1.92006\n",
      "[680]\ttraining's rmse: 1.98913\tvalid_1's rmse: 1.92003\n",
      "[681]\ttraining's rmse: 1.98911\tvalid_1's rmse: 1.92001\n",
      "[682]\ttraining's rmse: 1.98893\tvalid_1's rmse: 1.9199\n",
      "[683]\ttraining's rmse: 1.98847\tvalid_1's rmse: 1.9197\n",
      "[684]\ttraining's rmse: 1.98834\tvalid_1's rmse: 1.91967\n",
      "[685]\ttraining's rmse: 1.98833\tvalid_1's rmse: 1.91966\n",
      "[686]\ttraining's rmse: 1.98799\tvalid_1's rmse: 1.91925\n",
      "[687]\ttraining's rmse: 1.98788\tvalid_1's rmse: 1.91918\n",
      "[688]\ttraining's rmse: 1.98776\tvalid_1's rmse: 1.9191\n",
      "[689]\ttraining's rmse: 1.98728\tvalid_1's rmse: 1.91868\n",
      "[690]\ttraining's rmse: 1.98671\tvalid_1's rmse: 1.91777\n",
      "[691]\ttraining's rmse: 1.9864\tvalid_1's rmse: 1.91751\n",
      "[692]\ttraining's rmse: 1.98623\tvalid_1's rmse: 1.91744\n",
      "[693]\ttraining's rmse: 1.9862\tvalid_1's rmse: 1.91744\n",
      "[694]\ttraining's rmse: 1.98591\tvalid_1's rmse: 1.9172\n",
      "[695]\ttraining's rmse: 1.98549\tvalid_1's rmse: 1.91706\n",
      "[696]\ttraining's rmse: 1.98497\tvalid_1's rmse: 1.91688\n",
      "[697]\ttraining's rmse: 1.9849\tvalid_1's rmse: 1.91687\n",
      "[698]\ttraining's rmse: 1.98415\tvalid_1's rmse: 1.91672\n",
      "[699]\ttraining's rmse: 1.9841\tvalid_1's rmse: 1.91669\n",
      "[700]\ttraining's rmse: 1.98397\tvalid_1's rmse: 1.91645\n",
      "[701]\ttraining's rmse: 1.98394\tvalid_1's rmse: 1.91644\n",
      "[702]\ttraining's rmse: 1.98351\tvalid_1's rmse: 1.91593\n",
      "[703]\ttraining's rmse: 1.9833\tvalid_1's rmse: 1.91575\n",
      "[704]\ttraining's rmse: 1.98314\tvalid_1's rmse: 1.91565\n",
      "[705]\ttraining's rmse: 1.9831\tvalid_1's rmse: 1.91561\n",
      "[706]\ttraining's rmse: 1.98308\tvalid_1's rmse: 1.91561\n",
      "[707]\ttraining's rmse: 1.98303\tvalid_1's rmse: 1.91559\n",
      "[708]\ttraining's rmse: 1.98301\tvalid_1's rmse: 1.91559\n",
      "[709]\ttraining's rmse: 1.98285\tvalid_1's rmse: 1.91554\n",
      "[710]\ttraining's rmse: 1.98274\tvalid_1's rmse: 1.91554\n",
      "[711]\ttraining's rmse: 1.98271\tvalid_1's rmse: 1.91551\n",
      "[712]\ttraining's rmse: 1.98195\tvalid_1's rmse: 1.91498\n",
      "[713]\ttraining's rmse: 1.98183\tvalid_1's rmse: 1.91492\n",
      "[714]\ttraining's rmse: 1.98136\tvalid_1's rmse: 1.9142\n",
      "[715]\ttraining's rmse: 1.98081\tvalid_1's rmse: 1.91409\n",
      "[716]\ttraining's rmse: 1.98073\tvalid_1's rmse: 1.91406\n",
      "[717]\ttraining's rmse: 1.98065\tvalid_1's rmse: 1.91404\n",
      "[718]\ttraining's rmse: 1.97999\tvalid_1's rmse: 1.91377\n",
      "[719]\ttraining's rmse: 1.97988\tvalid_1's rmse: 1.91367\n",
      "[720]\ttraining's rmse: 1.97945\tvalid_1's rmse: 1.91341\n",
      "[721]\ttraining's rmse: 1.97866\tvalid_1's rmse: 1.91277\n",
      "[722]\ttraining's rmse: 1.97841\tvalid_1's rmse: 1.91268\n",
      "[723]\ttraining's rmse: 1.97757\tvalid_1's rmse: 1.91168\n",
      "[724]\ttraining's rmse: 1.97754\tvalid_1's rmse: 1.91168\n",
      "[725]\ttraining's rmse: 1.97736\tvalid_1's rmse: 1.91159\n",
      "[726]\ttraining's rmse: 1.97735\tvalid_1's rmse: 1.91158\n",
      "[727]\ttraining's rmse: 1.97717\tvalid_1's rmse: 1.91135\n",
      "[728]\ttraining's rmse: 1.97699\tvalid_1's rmse: 1.91136\n",
      "[729]\ttraining's rmse: 1.97645\tvalid_1's rmse: 1.91131\n",
      "[730]\ttraining's rmse: 1.97638\tvalid_1's rmse: 1.91124\n",
      "[731]\ttraining's rmse: 1.97577\tvalid_1's rmse: 1.91056\n",
      "[732]\ttraining's rmse: 1.97562\tvalid_1's rmse: 1.91037\n",
      "[733]\ttraining's rmse: 1.975\tvalid_1's rmse: 1.91024\n",
      "[734]\ttraining's rmse: 1.97497\tvalid_1's rmse: 1.91022\n",
      "[735]\ttraining's rmse: 1.97431\tvalid_1's rmse: 1.90947\n",
      "[736]\ttraining's rmse: 1.97395\tvalid_1's rmse: 1.90915\n",
      "[737]\ttraining's rmse: 1.97388\tvalid_1's rmse: 1.90911\n",
      "[738]\ttraining's rmse: 1.9737\tvalid_1's rmse: 1.90905\n",
      "[739]\ttraining's rmse: 1.97369\tvalid_1's rmse: 1.90905\n",
      "[740]\ttraining's rmse: 1.97298\tvalid_1's rmse: 1.90847\n",
      "[741]\ttraining's rmse: 1.97289\tvalid_1's rmse: 1.90841\n",
      "[742]\ttraining's rmse: 1.97258\tvalid_1's rmse: 1.90792\n",
      "[743]\ttraining's rmse: 1.97255\tvalid_1's rmse: 1.90789\n",
      "[744]\ttraining's rmse: 1.97221\tvalid_1's rmse: 1.90781\n",
      "[745]\ttraining's rmse: 1.97203\tvalid_1's rmse: 1.90779\n",
      "[746]\ttraining's rmse: 1.97186\tvalid_1's rmse: 1.90766\n",
      "[747]\ttraining's rmse: 1.97169\tvalid_1's rmse: 1.90751\n",
      "[748]\ttraining's rmse: 1.97104\tvalid_1's rmse: 1.9072\n",
      "[749]\ttraining's rmse: 1.9709\tvalid_1's rmse: 1.90675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\ttraining's rmse: 1.97086\tvalid_1's rmse: 1.90672\n",
      "[751]\ttraining's rmse: 1.97071\tvalid_1's rmse: 1.90674\n",
      "[752]\ttraining's rmse: 1.97067\tvalid_1's rmse: 1.90669\n",
      "[753]\ttraining's rmse: 1.97046\tvalid_1's rmse: 1.90666\n",
      "[754]\ttraining's rmse: 1.97025\tvalid_1's rmse: 1.90643\n",
      "[755]\ttraining's rmse: 1.97021\tvalid_1's rmse: 1.90643\n",
      "[756]\ttraining's rmse: 1.97001\tvalid_1's rmse: 1.90619\n",
      "[757]\ttraining's rmse: 1.96996\tvalid_1's rmse: 1.90617\n",
      "[758]\ttraining's rmse: 1.96967\tvalid_1's rmse: 1.90609\n",
      "[759]\ttraining's rmse: 1.96931\tvalid_1's rmse: 1.90587\n",
      "[760]\ttraining's rmse: 1.96891\tvalid_1's rmse: 1.90553\n",
      "[761]\ttraining's rmse: 1.96867\tvalid_1's rmse: 1.90534\n",
      "[762]\ttraining's rmse: 1.96853\tvalid_1's rmse: 1.90522\n",
      "[763]\ttraining's rmse: 1.96849\tvalid_1's rmse: 1.90513\n",
      "[764]\ttraining's rmse: 1.96828\tvalid_1's rmse: 1.90501\n",
      "[765]\ttraining's rmse: 1.96825\tvalid_1's rmse: 1.90498\n",
      "[766]\ttraining's rmse: 1.96822\tvalid_1's rmse: 1.90496\n",
      "[767]\ttraining's rmse: 1.96813\tvalid_1's rmse: 1.90488\n",
      "[768]\ttraining's rmse: 1.96733\tvalid_1's rmse: 1.90466\n",
      "[769]\ttraining's rmse: 1.96724\tvalid_1's rmse: 1.90463\n",
      "[770]\ttraining's rmse: 1.96707\tvalid_1's rmse: 1.90452\n",
      "[771]\ttraining's rmse: 1.96705\tvalid_1's rmse: 1.9045\n",
      "[772]\ttraining's rmse: 1.96654\tvalid_1's rmse: 1.90422\n",
      "[773]\ttraining's rmse: 1.96623\tvalid_1's rmse: 1.90404\n",
      "[774]\ttraining's rmse: 1.96581\tvalid_1's rmse: 1.90382\n",
      "[775]\ttraining's rmse: 1.9658\tvalid_1's rmse: 1.90381\n",
      "[776]\ttraining's rmse: 1.9655\tvalid_1's rmse: 1.90358\n",
      "[777]\ttraining's rmse: 1.9655\tvalid_1's rmse: 1.90358\n",
      "[778]\ttraining's rmse: 1.96547\tvalid_1's rmse: 1.90355\n",
      "[779]\ttraining's rmse: 1.96489\tvalid_1's rmse: 1.90309\n",
      "[780]\ttraining's rmse: 1.96482\tvalid_1's rmse: 1.90306\n",
      "[781]\ttraining's rmse: 1.96476\tvalid_1's rmse: 1.90293\n",
      "[782]\ttraining's rmse: 1.96474\tvalid_1's rmse: 1.90293\n",
      "[783]\ttraining's rmse: 1.96432\tvalid_1's rmse: 1.90259\n",
      "[784]\ttraining's rmse: 1.96395\tvalid_1's rmse: 1.90236\n",
      "[785]\ttraining's rmse: 1.96357\tvalid_1's rmse: 1.90186\n",
      "[786]\ttraining's rmse: 1.96343\tvalid_1's rmse: 1.90159\n",
      "[787]\ttraining's rmse: 1.96321\tvalid_1's rmse: 1.90139\n",
      "[788]\ttraining's rmse: 1.9632\tvalid_1's rmse: 1.90137\n",
      "[789]\ttraining's rmse: 1.96302\tvalid_1's rmse: 1.90125\n",
      "[790]\ttraining's rmse: 1.96267\tvalid_1's rmse: 1.90091\n",
      "[791]\ttraining's rmse: 1.96253\tvalid_1's rmse: 1.90073\n",
      "[792]\ttraining's rmse: 1.96251\tvalid_1's rmse: 1.90072\n",
      "[793]\ttraining's rmse: 1.9624\tvalid_1's rmse: 1.90069\n",
      "[794]\ttraining's rmse: 1.9624\tvalid_1's rmse: 1.90068\n",
      "[795]\ttraining's rmse: 1.96233\tvalid_1's rmse: 1.9006\n",
      "[796]\ttraining's rmse: 1.9617\tvalid_1's rmse: 1.9005\n",
      "[797]\ttraining's rmse: 1.96169\tvalid_1's rmse: 1.9005\n",
      "[798]\ttraining's rmse: 1.96167\tvalid_1's rmse: 1.90049\n",
      "[799]\ttraining's rmse: 1.96147\tvalid_1's rmse: 1.9003\n",
      "[800]\ttraining's rmse: 1.96136\tvalid_1's rmse: 1.90021\n",
      "[801]\ttraining's rmse: 1.96126\tvalid_1's rmse: 1.9001\n",
      "[802]\ttraining's rmse: 1.96116\tvalid_1's rmse: 1.90013\n",
      "[803]\ttraining's rmse: 1.96077\tvalid_1's rmse: 1.90009\n",
      "[804]\ttraining's rmse: 1.96068\tvalid_1's rmse: 1.90007\n",
      "[805]\ttraining's rmse: 1.9606\tvalid_1's rmse: 1.89999\n",
      "[806]\ttraining's rmse: 1.9602\tvalid_1's rmse: 1.89958\n",
      "[807]\ttraining's rmse: 1.95994\tvalid_1's rmse: 1.89943\n",
      "[808]\ttraining's rmse: 1.95979\tvalid_1's rmse: 1.89928\n",
      "[809]\ttraining's rmse: 1.95952\tvalid_1's rmse: 1.89912\n",
      "[810]\ttraining's rmse: 1.9595\tvalid_1's rmse: 1.89911\n",
      "[811]\ttraining's rmse: 1.95923\tvalid_1's rmse: 1.89889\n",
      "[812]\ttraining's rmse: 1.95922\tvalid_1's rmse: 1.89888\n",
      "[813]\ttraining's rmse: 1.95891\tvalid_1's rmse: 1.89874\n",
      "[814]\ttraining's rmse: 1.95833\tvalid_1's rmse: 1.89849\n",
      "[815]\ttraining's rmse: 1.95805\tvalid_1's rmse: 1.89823\n",
      "[816]\ttraining's rmse: 1.95781\tvalid_1's rmse: 1.8981\n",
      "[817]\ttraining's rmse: 1.95769\tvalid_1's rmse: 1.8981\n",
      "[818]\ttraining's rmse: 1.95741\tvalid_1's rmse: 1.89805\n",
      "[819]\ttraining's rmse: 1.95705\tvalid_1's rmse: 1.8978\n",
      "[820]\ttraining's rmse: 1.95651\tvalid_1's rmse: 1.89737\n",
      "[821]\ttraining's rmse: 1.9565\tvalid_1's rmse: 1.89734\n",
      "[822]\ttraining's rmse: 1.95602\tvalid_1's rmse: 1.89686\n",
      "[823]\ttraining's rmse: 1.95588\tvalid_1's rmse: 1.89683\n",
      "[824]\ttraining's rmse: 1.95567\tvalid_1's rmse: 1.89657\n",
      "[825]\ttraining's rmse: 1.95548\tvalid_1's rmse: 1.89623\n",
      "[826]\ttraining's rmse: 1.95543\tvalid_1's rmse: 1.89622\n",
      "[827]\ttraining's rmse: 1.95535\tvalid_1's rmse: 1.89613\n",
      "[828]\ttraining's rmse: 1.95527\tvalid_1's rmse: 1.89603\n",
      "[829]\ttraining's rmse: 1.95495\tvalid_1's rmse: 1.89573\n",
      "[830]\ttraining's rmse: 1.95477\tvalid_1's rmse: 1.89553\n",
      "[831]\ttraining's rmse: 1.95453\tvalid_1's rmse: 1.89379\n",
      "[832]\ttraining's rmse: 1.95426\tvalid_1's rmse: 1.89367\n",
      "[833]\ttraining's rmse: 1.95419\tvalid_1's rmse: 1.89367\n",
      "[834]\ttraining's rmse: 1.95419\tvalid_1's rmse: 1.89367\n",
      "[835]\ttraining's rmse: 1.95406\tvalid_1's rmse: 1.89359\n",
      "[836]\ttraining's rmse: 1.95375\tvalid_1's rmse: 1.89328\n",
      "[837]\ttraining's rmse: 1.95366\tvalid_1's rmse: 1.89328\n",
      "[838]\ttraining's rmse: 1.95328\tvalid_1's rmse: 1.89283\n",
      "[839]\ttraining's rmse: 1.95318\tvalid_1's rmse: 1.89277\n",
      "[840]\ttraining's rmse: 1.95308\tvalid_1's rmse: 1.89276\n",
      "[841]\ttraining's rmse: 1.95294\tvalid_1's rmse: 1.89266\n",
      "[842]\ttraining's rmse: 1.95269\tvalid_1's rmse: 1.89231\n",
      "[843]\ttraining's rmse: 1.95268\tvalid_1's rmse: 1.89231\n",
      "[844]\ttraining's rmse: 1.95252\tvalid_1's rmse: 1.89222\n",
      "[845]\ttraining's rmse: 1.95242\tvalid_1's rmse: 1.89221\n",
      "[846]\ttraining's rmse: 1.95224\tvalid_1's rmse: 1.8921\n",
      "[847]\ttraining's rmse: 1.95174\tvalid_1's rmse: 1.89204\n",
      "[848]\ttraining's rmse: 1.95168\tvalid_1's rmse: 1.89201\n",
      "[849]\ttraining's rmse: 1.95166\tvalid_1's rmse: 1.892\n",
      "[850]\ttraining's rmse: 1.95128\tvalid_1's rmse: 1.89161\n",
      "[851]\ttraining's rmse: 1.95084\tvalid_1's rmse: 1.89117\n",
      "[852]\ttraining's rmse: 1.95014\tvalid_1's rmse: 1.89033\n",
      "[853]\ttraining's rmse: 1.95004\tvalid_1's rmse: 1.89029\n",
      "[854]\ttraining's rmse: 1.94963\tvalid_1's rmse: 1.88819\n",
      "[855]\ttraining's rmse: 1.94929\tvalid_1's rmse: 1.88788\n",
      "[856]\ttraining's rmse: 1.94921\tvalid_1's rmse: 1.88788\n",
      "[857]\ttraining's rmse: 1.9486\tvalid_1's rmse: 1.88741\n",
      "[858]\ttraining's rmse: 1.94828\tvalid_1's rmse: 1.88714\n",
      "[859]\ttraining's rmse: 1.94784\tvalid_1's rmse: 1.88706\n",
      "[860]\ttraining's rmse: 1.94776\tvalid_1's rmse: 1.88705\n",
      "[861]\ttraining's rmse: 1.94767\tvalid_1's rmse: 1.88685\n",
      "[862]\ttraining's rmse: 1.94765\tvalid_1's rmse: 1.88684\n",
      "[863]\ttraining's rmse: 1.94754\tvalid_1's rmse: 1.88684\n",
      "[864]\ttraining's rmse: 1.94721\tvalid_1's rmse: 1.88658\n",
      "[865]\ttraining's rmse: 1.94678\tvalid_1's rmse: 1.88642\n",
      "[866]\ttraining's rmse: 1.94666\tvalid_1's rmse: 1.88631\n",
      "[867]\ttraining's rmse: 1.94666\tvalid_1's rmse: 1.8863\n",
      "[868]\ttraining's rmse: 1.94607\tvalid_1's rmse: 1.88597\n",
      "[869]\ttraining's rmse: 1.94602\tvalid_1's rmse: 1.88595\n",
      "[870]\ttraining's rmse: 1.94584\tvalid_1's rmse: 1.88584\n",
      "[871]\ttraining's rmse: 1.94575\tvalid_1's rmse: 1.88584\n",
      "[872]\ttraining's rmse: 1.94572\tvalid_1's rmse: 1.88582\n",
      "[873]\ttraining's rmse: 1.94557\tvalid_1's rmse: 1.88577\n",
      "[874]\ttraining's rmse: 1.94521\tvalid_1's rmse: 1.88558\n",
      "[875]\ttraining's rmse: 1.94519\tvalid_1's rmse: 1.88557\n",
      "[876]\ttraining's rmse: 1.94513\tvalid_1's rmse: 1.88559\n",
      "[877]\ttraining's rmse: 1.94419\tvalid_1's rmse: 1.88489\n",
      "[878]\ttraining's rmse: 1.94412\tvalid_1's rmse: 1.88474\n",
      "[879]\ttraining's rmse: 1.94406\tvalid_1's rmse: 1.88471\n",
      "[880]\ttraining's rmse: 1.94404\tvalid_1's rmse: 1.88471\n",
      "[881]\ttraining's rmse: 1.94397\tvalid_1's rmse: 1.88469\n",
      "[882]\ttraining's rmse: 1.94396\tvalid_1's rmse: 1.88469\n",
      "[883]\ttraining's rmse: 1.94382\tvalid_1's rmse: 1.88463\n",
      "[884]\ttraining's rmse: 1.94341\tvalid_1's rmse: 1.88422\n",
      "[885]\ttraining's rmse: 1.9434\tvalid_1's rmse: 1.88421\n",
      "[886]\ttraining's rmse: 1.94327\tvalid_1's rmse: 1.88418\n",
      "[887]\ttraining's rmse: 1.94321\tvalid_1's rmse: 1.88406\n",
      "[888]\ttraining's rmse: 1.94214\tvalid_1's rmse: 1.88382\n",
      "[889]\ttraining's rmse: 1.94212\tvalid_1's rmse: 1.88381\n",
      "[890]\ttraining's rmse: 1.94211\tvalid_1's rmse: 1.88381\n",
      "[891]\ttraining's rmse: 1.94208\tvalid_1's rmse: 1.88379\n",
      "[892]\ttraining's rmse: 1.94198\tvalid_1's rmse: 1.88364\n",
      "[893]\ttraining's rmse: 1.94168\tvalid_1's rmse: 1.88248\n",
      "[894]\ttraining's rmse: 1.94143\tvalid_1's rmse: 1.88217\n",
      "[895]\ttraining's rmse: 1.94139\tvalid_1's rmse: 1.88211\n",
      "[896]\ttraining's rmse: 1.94089\tvalid_1's rmse: 1.88199\n",
      "[897]\ttraining's rmse: 1.94088\tvalid_1's rmse: 1.88198\n",
      "[898]\ttraining's rmse: 1.94042\tvalid_1's rmse: 1.88177\n",
      "[899]\ttraining's rmse: 1.94033\tvalid_1's rmse: 1.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's rmse: 1.94017\tvalid_1's rmse: 1.88042\n",
      "[901]\ttraining's rmse: 1.93951\tvalid_1's rmse: 1.87984\n",
      "[902]\ttraining's rmse: 1.93949\tvalid_1's rmse: 1.87982\n",
      "[903]\ttraining's rmse: 1.93938\tvalid_1's rmse: 1.87976\n",
      "[904]\ttraining's rmse: 1.93935\tvalid_1's rmse: 1.87974\n",
      "[905]\ttraining's rmse: 1.93894\tvalid_1's rmse: 1.8794\n",
      "[906]\ttraining's rmse: 1.93865\tvalid_1's rmse: 1.87916\n",
      "[907]\ttraining's rmse: 1.93841\tvalid_1's rmse: 1.87768\n",
      "[908]\ttraining's rmse: 1.93826\tvalid_1's rmse: 1.87768\n",
      "[909]\ttraining's rmse: 1.93801\tvalid_1's rmse: 1.8776\n",
      "[910]\ttraining's rmse: 1.93729\tvalid_1's rmse: 1.87709\n",
      "[911]\ttraining's rmse: 1.93716\tvalid_1's rmse: 1.87714\n",
      "[912]\ttraining's rmse: 1.93714\tvalid_1's rmse: 1.87714\n",
      "[913]\ttraining's rmse: 1.93713\tvalid_1's rmse: 1.87714\n",
      "[914]\ttraining's rmse: 1.93664\tvalid_1's rmse: 1.87704\n",
      "[915]\ttraining's rmse: 1.93661\tvalid_1's rmse: 1.87701\n",
      "[916]\ttraining's rmse: 1.93578\tvalid_1's rmse: 1.8767\n",
      "[917]\ttraining's rmse: 1.93576\tvalid_1's rmse: 1.8767\n",
      "[918]\ttraining's rmse: 1.93545\tvalid_1's rmse: 1.87592\n",
      "[919]\ttraining's rmse: 1.93517\tvalid_1's rmse: 1.87562\n",
      "[920]\ttraining's rmse: 1.93504\tvalid_1's rmse: 1.8755\n",
      "[921]\ttraining's rmse: 1.93486\tvalid_1's rmse: 1.87536\n",
      "[922]\ttraining's rmse: 1.93476\tvalid_1's rmse: 1.87531\n",
      "[923]\ttraining's rmse: 1.93475\tvalid_1's rmse: 1.87531\n",
      "[924]\ttraining's rmse: 1.93436\tvalid_1's rmse: 1.87504\n",
      "[925]\ttraining's rmse: 1.93425\tvalid_1's rmse: 1.87498\n",
      "[926]\ttraining's rmse: 1.93404\tvalid_1's rmse: 1.87472\n",
      "[927]\ttraining's rmse: 1.93361\tvalid_1's rmse: 1.87437\n",
      "[928]\ttraining's rmse: 1.93314\tvalid_1's rmse: 1.87387\n",
      "[929]\ttraining's rmse: 1.93286\tvalid_1's rmse: 1.87361\n",
      "[930]\ttraining's rmse: 1.93268\tvalid_1's rmse: 1.87335\n",
      "[931]\ttraining's rmse: 1.93266\tvalid_1's rmse: 1.87334\n",
      "[932]\ttraining's rmse: 1.9326\tvalid_1's rmse: 1.87332\n",
      "[933]\ttraining's rmse: 1.93242\tvalid_1's rmse: 1.87136\n",
      "[934]\ttraining's rmse: 1.93236\tvalid_1's rmse: 1.87131\n",
      "[935]\ttraining's rmse: 1.93221\tvalid_1's rmse: 1.87119\n",
      "[936]\ttraining's rmse: 1.93211\tvalid_1's rmse: 1.87117\n",
      "[937]\ttraining's rmse: 1.93187\tvalid_1's rmse: 1.87091\n",
      "[938]\ttraining's rmse: 1.93154\tvalid_1's rmse: 1.87079\n",
      "[939]\ttraining's rmse: 1.93139\tvalid_1's rmse: 1.87069\n",
      "[940]\ttraining's rmse: 1.93138\tvalid_1's rmse: 1.87069\n",
      "[941]\ttraining's rmse: 1.93088\tvalid_1's rmse: 1.87037\n",
      "[942]\ttraining's rmse: 1.93072\tvalid_1's rmse: 1.87023\n",
      "[943]\ttraining's rmse: 1.93003\tvalid_1's rmse: 1.86972\n",
      "[944]\ttraining's rmse: 1.92989\tvalid_1's rmse: 1.86838\n",
      "[945]\ttraining's rmse: 1.92977\tvalid_1's rmse: 1.86836\n",
      "[946]\ttraining's rmse: 1.92959\tvalid_1's rmse: 1.86818\n",
      "[947]\ttraining's rmse: 1.92949\tvalid_1's rmse: 1.86818\n",
      "[948]\ttraining's rmse: 1.92946\tvalid_1's rmse: 1.86815\n",
      "[949]\ttraining's rmse: 1.92938\tvalid_1's rmse: 1.86815\n",
      "[950]\ttraining's rmse: 1.92902\tvalid_1's rmse: 1.86783\n",
      "[951]\ttraining's rmse: 1.92886\tvalid_1's rmse: 1.86775\n",
      "[952]\ttraining's rmse: 1.92858\tvalid_1's rmse: 1.86759\n",
      "[953]\ttraining's rmse: 1.92815\tvalid_1's rmse: 1.86706\n",
      "[954]\ttraining's rmse: 1.92807\tvalid_1's rmse: 1.86702\n",
      "[955]\ttraining's rmse: 1.92798\tvalid_1's rmse: 1.86692\n",
      "[956]\ttraining's rmse: 1.92785\tvalid_1's rmse: 1.86688\n",
      "[957]\ttraining's rmse: 1.92783\tvalid_1's rmse: 1.86687\n",
      "[958]\ttraining's rmse: 1.92775\tvalid_1's rmse: 1.86672\n",
      "[959]\ttraining's rmse: 1.92733\tvalid_1's rmse: 1.86628\n",
      "[960]\ttraining's rmse: 1.92722\tvalid_1's rmse: 1.86622\n",
      "[961]\ttraining's rmse: 1.92719\tvalid_1's rmse: 1.86621\n",
      "[962]\ttraining's rmse: 1.92716\tvalid_1's rmse: 1.86619\n",
      "[963]\ttraining's rmse: 1.92693\tvalid_1's rmse: 1.86611\n",
      "[964]\ttraining's rmse: 1.92668\tvalid_1's rmse: 1.86605\n",
      "[965]\ttraining's rmse: 1.92658\tvalid_1's rmse: 1.86588\n",
      "[966]\ttraining's rmse: 1.92651\tvalid_1's rmse: 1.86581\n",
      "[967]\ttraining's rmse: 1.92611\tvalid_1's rmse: 1.86564\n",
      "[968]\ttraining's rmse: 1.92562\tvalid_1's rmse: 1.86538\n",
      "[969]\ttraining's rmse: 1.9255\tvalid_1's rmse: 1.86535\n",
      "[970]\ttraining's rmse: 1.92449\tvalid_1's rmse: 1.86482\n",
      "[971]\ttraining's rmse: 1.92395\tvalid_1's rmse: 1.86444\n",
      "[972]\ttraining's rmse: 1.92395\tvalid_1's rmse: 1.86444\n",
      "[973]\ttraining's rmse: 1.92385\tvalid_1's rmse: 1.86435\n",
      "[974]\ttraining's rmse: 1.92381\tvalid_1's rmse: 1.86433\n",
      "[975]\ttraining's rmse: 1.92365\tvalid_1's rmse: 1.86412\n",
      "[976]\ttraining's rmse: 1.92357\tvalid_1's rmse: 1.86412\n",
      "[977]\ttraining's rmse: 1.92333\tvalid_1's rmse: 1.86395\n",
      "[978]\ttraining's rmse: 1.92328\tvalid_1's rmse: 1.86394\n",
      "[979]\ttraining's rmse: 1.92318\tvalid_1's rmse: 1.86392\n",
      "[980]\ttraining's rmse: 1.92306\tvalid_1's rmse: 1.86388\n",
      "[981]\ttraining's rmse: 1.92292\tvalid_1's rmse: 1.86387\n",
      "[982]\ttraining's rmse: 1.92266\tvalid_1's rmse: 1.86372\n",
      "[983]\ttraining's rmse: 1.92264\tvalid_1's rmse: 1.86372\n",
      "[984]\ttraining's rmse: 1.92262\tvalid_1's rmse: 1.8637\n",
      "[985]\ttraining's rmse: 1.92225\tvalid_1's rmse: 1.86361\n",
      "[986]\ttraining's rmse: 1.92207\tvalid_1's rmse: 1.86358\n",
      "[987]\ttraining's rmse: 1.92193\tvalid_1's rmse: 1.86353\n",
      "[988]\ttraining's rmse: 1.92191\tvalid_1's rmse: 1.86351\n",
      "[989]\ttraining's rmse: 1.9219\tvalid_1's rmse: 1.86351\n",
      "[990]\ttraining's rmse: 1.92179\tvalid_1's rmse: 1.86347\n",
      "[991]\ttraining's rmse: 1.92134\tvalid_1's rmse: 1.86324\n",
      "[992]\ttraining's rmse: 1.92134\tvalid_1's rmse: 1.86324\n",
      "[993]\ttraining's rmse: 1.92132\tvalid_1's rmse: 1.86322\n",
      "[994]\ttraining's rmse: 1.92129\tvalid_1's rmse: 1.86319\n",
      "[995]\ttraining's rmse: 1.92109\tvalid_1's rmse: 1.86303\n",
      "[996]\ttraining's rmse: 1.92061\tvalid_1's rmse: 1.86251\n",
      "[997]\ttraining's rmse: 1.9203\tvalid_1's rmse: 1.8619\n",
      "[998]\ttraining's rmse: 1.92001\tvalid_1's rmse: 1.8616\n",
      "[999]\ttraining's rmse: 1.91993\tvalid_1's rmse: 1.86141\n",
      "[1000]\ttraining's rmse: 1.91954\tvalid_1's rmse: 1.86118\n",
      "Wall time: 20min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=LGBMRegressor(), n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={'bagging_fraction': [0.5, 0.7],\n",
       "                                        'boosting_type': ['gbdt'],\n",
       "                                        'feature_fraction': [0.5, 0.7],\n",
       "                                        'learning_rate': [0.03, 0.1, 0.3],\n",
       "                                        'max_depth': [10, 30, 50],\n",
       "                                        'metric': ['rmse'],\n",
       "                                        'n_estimators': [500, 1000],\n",
       "                                        'num_leaves': [50, 100, 250, 500],\n",
       "                                        'objective': ['tweedie'],\n",
       "                                        'tweedie_variance_power': [1.1, 1.3,\n",
       "                                                                   1.5]},\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running a randomized search for hyperparameters of LGBM Regressor using a time series cross validation of 5 splits\n",
    "\n",
    "%%time\n",
    "\n",
    "lgbm_estimator = LGBMRegressor()\n",
    "\n",
    "param_distributions = {'boosting_type': ['gbdt'],\n",
    "                       'objective': ['tweedie'],\n",
    "                       'tweedie_variance_power': [1.1, 1.3, 1.5],\n",
    "                       'n_estimators': [500, 1000],\n",
    "                       'metric': ['rmse'],\n",
    "                       'max_depth': [10, 30, 50],\n",
    "                       'num_leaves': [50, 100, 250, 500],\n",
    "                       'learning_rate': [0.03, 0.1, 0.3],\n",
    "                       'feature_fraction': [0.5, 0.7],\n",
    "                       'bagging_fraction': [0.5, 0.7]}\n",
    "\n",
    "n_iter = 1\n",
    "\n",
    "time_series_split = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "randomized_search_cv = RandomizedSearchCV(estimator = lgbm_estimator,\n",
    "                                   param_distributions = param_distributions,\n",
    "                                   n_iter = n_iter,\n",
    "                                   cv = time_series_split,\n",
    "                                   scoring = 'neg_mean_squared_error',\n",
    "                                   n_jobs = -1)\n",
    "\n",
    "randomized_search_cv.fit(X_train,\n",
    "                         y_train,\n",
    "                         eval_metric = 'rmse',\n",
    "                         eval_set = [(X_train, y_train), (X_validation, y_validation)],\n",
    "                         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stretch-dallas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.7, feature_fraction=0.5, learning_rate=0.03,\n",
       "              max_depth=10, metric='rmse', n_estimators=1000, num_leaves=250,\n",
       "              objective='tweedie', tweedie_variance_power=1.3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters of the best estimator obtained by the randomized search\n",
    "# we do not need to run this step again\n",
    "\n",
    "randomized_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inclusive-algorithm",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] num_iterations is set=1000, n_iter=1000 will be ignored. Current value: num_iterations=1000\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's rmse: 3.3074\n",
      "[40]\ttraining's rmse: 2.8196\n",
      "[60]\ttraining's rmse: 2.48248\n",
      "[80]\ttraining's rmse: 2.31131\n",
      "[100]\ttraining's rmse: 2.23027\n",
      "[120]\ttraining's rmse: 2.19243\n",
      "[140]\ttraining's rmse: 2.16832\n",
      "[160]\ttraining's rmse: 2.15238\n",
      "[180]\ttraining's rmse: 2.13978\n",
      "[200]\ttraining's rmse: 2.12992\n",
      "[220]\ttraining's rmse: 2.12245\n",
      "[240]\ttraining's rmse: 2.11535\n",
      "[260]\ttraining's rmse: 2.10995\n",
      "[280]\ttraining's rmse: 2.10216\n",
      "[300]\ttraining's rmse: 2.09585\n",
      "[320]\ttraining's rmse: 2.08913\n",
      "[340]\ttraining's rmse: 2.08379\n",
      "[360]\ttraining's rmse: 2.07802\n",
      "[380]\ttraining's rmse: 2.07192\n",
      "[400]\ttraining's rmse: 2.06492\n",
      "[420]\ttraining's rmse: 2.05892\n",
      "[440]\ttraining's rmse: 2.05184\n",
      "[460]\ttraining's rmse: 2.0443\n",
      "[480]\ttraining's rmse: 2.03818\n",
      "[500]\ttraining's rmse: 2.03357\n",
      "[520]\ttraining's rmse: 2.0272\n",
      "[540]\ttraining's rmse: 2.02263\n",
      "[560]\ttraining's rmse: 2.0182\n",
      "[580]\ttraining's rmse: 2.01305\n",
      "[600]\ttraining's rmse: 2.00857\n",
      "[620]\ttraining's rmse: 2.00304\n",
      "[640]\ttraining's rmse: 1.99867\n",
      "[660]\ttraining's rmse: 1.99321\n",
      "[680]\ttraining's rmse: 1.98913\n",
      "[700]\ttraining's rmse: 1.98397\n",
      "[720]\ttraining's rmse: 1.97945\n",
      "[740]\ttraining's rmse: 1.97298\n",
      "[760]\ttraining's rmse: 1.96891\n",
      "[780]\ttraining's rmse: 1.96482\n",
      "[800]\ttraining's rmse: 1.96136\n",
      "[820]\ttraining's rmse: 1.95651\n",
      "[840]\ttraining's rmse: 1.95308\n",
      "[860]\ttraining's rmse: 1.94776\n",
      "[880]\ttraining's rmse: 1.94404\n",
      "[900]\ttraining's rmse: 1.94017\n",
      "[920]\ttraining's rmse: 1.93504\n",
      "[940]\ttraining's rmse: 1.93138\n",
      "[960]\ttraining's rmse: 1.92722\n",
      "[980]\ttraining's rmse: 1.92306\n",
      "[1000]\ttraining's rmse: 1.91954\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 1.91954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1fc02b52080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training an LGBM Regressor over the entire training set using the best hyperparameters obtained above\n",
    "# saving to model to disk for later use\n",
    "\n",
    "X_train = train.drop('units_sold', axis = 1)\n",
    "y_train = train['units_sold']\n",
    "\n",
    "lgbm_regressor_model = LGBMRegressor(objective = 'tweedie',\n",
    "                                     tweedie_variance_power = 1.3,\n",
    "                                     boosting_type = 'gbdt',\n",
    "                                     metric = 'rmse',\n",
    "                                     n_estimators = 1000,\n",
    "                                     num_leaves = 250,\n",
    "                                     max_depth = 10,\n",
    "                                     learning_rate = 0.03,\n",
    "                                     feature_fraction = 0.5,\n",
    "                                     bagging_fraction = 0.7,\n",
    "                                     n_iter = 1000)\n",
    "\n",
    "lgbm_regressor_model.fit(X_train, y_train, eval_set = [(X_train, y_train)], \\\n",
    "                         eval_metric = 'rmse', early_stopping_rounds = 20, verbose = 20)\n",
    "\n",
    "lgbm_regressor_model.booster_.save_model('C:/Big Data Project/Models/lgbm_regressor_model.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brave-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the LGBM Regressor model from the disk\n",
    "# obtain predictions over the test set and evaluate using the metric rmse\n",
    "\n",
    "lgbm_regressor_model = Booster(model_file = 'C:/Big Data Project/Models/lgbm_regressor_model.mdl')\n",
    "\n",
    "y_test_predictions = lgbm_regressor_model.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "communist-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1234526334106243"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "european-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain feature importances from the LGBM Regressor generated\n",
    "\n",
    "feature_importances_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': lgbm_regressor_model.feature_importance()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0,
          901,
          1952,
          12525,
          5430,
          10193,
          3682,
          3372,
          1357,
          62,
          40,
          2397,
          1267,
          1148,
          11968,
          5081,
          5366,
          4993,
          3739,
          4024,
          4187,
          4127,
          11423,
          2932,
          702,
          0,
          8329,
          9300,
          10846,
          12274,
          14266,
          9889,
          9988,
          14421,
          12580,
          8902,
          8821,
          5302,
          14049
         ],
         "xaxis": "x",
         "y": [
          "store_id",
          "cat_id",
          "dept_id",
          "item_id",
          "wday",
          "month",
          "year",
          "event_name_1",
          "event_type_1",
          "event_name_2",
          "event_type_2",
          "snap_CA",
          "snap_TX",
          "snap_WI",
          "sell_price",
          "sold_lag_7",
          "sold_lag_14",
          "sold_lag_21",
          "sold_lag_28",
          "sold_lag_35",
          "sold_lag_42",
          "sold_lag_49",
          "item_mean",
          "dept_mean",
          "cat_mean",
          "store_mean",
          "sold_rolling_mean_window_7_lag_28",
          "sold_rolling_mean_window_14_lag_28",
          "sold_rolling_mean_window_28_lag_28",
          "sold_rolling_mean_window_56_lag_28",
          "sold_rolling_mean_window_112_lag_28",
          "sold_rolling_mean_window_7_lag_7",
          "sold_rolling_mean_window_7_lag_365",
          "sold_expanding_mean_lag_7",
          "sold_expanding_mean_lag_365",
          "price_rolling_mean_window_7_lag_1",
          "price_rolling_max_window_365_lag_1",
          "sold_revenue_lag_28",
          "variance_trend_lag_7"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 800,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Feature Importance Plot: Random Forests Regression"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryorder": "total ascending",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Feature"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d181241d-a241-4ea4-8876-2652fb185398\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d181241d-a241-4ea4-8876-2652fb185398\")) {                    Plotly.newPlot(                        \"d181241d-a241-4ea4-8876-2652fb185398\",                        [{\"alignmentgroup\": \"True\", \"hovertemplate\": \"Importance=%{x}<br>Feature=%{y}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"h\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [0, 901, 1952, 12525, 5430, 10193, 3682, 3372, 1357, 62, 40, 2397, 1267, 1148, 11968, 5081, 5366, 4993, 3739, 4024, 4187, 4127, 11423, 2932, 702, 0, 8329, 9300, 10846, 12274, 14266, 9889, 9988, 14421, 12580, 8902, 8821, 5302, 14049], \"xaxis\": \"x\", \"y\": [\"store_id\", \"cat_id\", \"dept_id\", \"item_id\", \"wday\", \"month\", \"year\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\", \"sell_price\", \"sold_lag_7\", \"sold_lag_14\", \"sold_lag_21\", \"sold_lag_28\", \"sold_lag_35\", \"sold_lag_42\", \"sold_lag_49\", \"item_mean\", \"dept_mean\", \"cat_mean\", \"store_mean\", \"sold_rolling_mean_window_7_lag_28\", \"sold_rolling_mean_window_14_lag_28\", \"sold_rolling_mean_window_28_lag_28\", \"sold_rolling_mean_window_56_lag_28\", \"sold_rolling_mean_window_112_lag_28\", \"sold_rolling_mean_window_7_lag_7\", \"sold_rolling_mean_window_7_lag_365\", \"sold_expanding_mean_lag_7\", \"sold_expanding_mean_lag_365\", \"price_rolling_mean_window_7_lag_1\", \"price_rolling_max_window_365_lag_1\", \"sold_revenue_lag_28\", \"variance_trend_lag_7\"], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"height\": 800, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"rgb(36,36,36)\"}, \"error_y\": {\"color\": \"rgb(36,36,36)\"}, \"marker\": {\"line\": {\"color\": \"rgb(234,234,242)\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"rgb(234,234,242)\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"rgb(36,36,36)\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"rgb(36,36,36)\"}, \"baxis\": {\"endlinecolor\": \"rgb(36,36,36)\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"rgb(36,36,36)\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"colorscale\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"colorscale\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"colorscale\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"colorscale\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"colorscale\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}, \"colorscale\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"rgb(231,231,240)\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"rgb(183,183,191)\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"rgb(67,103,167)\"}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"tickcolor\": \"rgb(36,36,36)\", \"ticklen\": 8, \"ticks\": \"outside\", \"tickwidth\": 2}}, \"colorscale\": {\"sequential\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]], \"sequentialminus\": [[0.0, \"rgb(2,4,25)\"], [0.06274509803921569, \"rgb(24,15,41)\"], [0.12549019607843137, \"rgb(47,23,57)\"], [0.18823529411764706, \"rgb(71,28,72)\"], [0.25098039215686274, \"rgb(97,30,82)\"], [0.3137254901960784, \"rgb(123,30,89)\"], [0.3764705882352941, \"rgb(150,27,91)\"], [0.4392156862745098, \"rgb(177,22,88)\"], [0.5019607843137255, \"rgb(203,26,79)\"], [0.5647058823529412, \"rgb(223,47,67)\"], [0.6274509803921569, \"rgb(236,76,61)\"], [0.6901960784313725, \"rgb(242,107,73)\"], [0.7529411764705882, \"rgb(244,135,95)\"], [0.8156862745098039, \"rgb(245,162,122)\"], [0.8784313725490196, \"rgb(246,188,153)\"], [0.9411764705882353, \"rgb(247,212,187)\"], [1.0, \"rgb(250,234,220)\"]]}, \"colorway\": [\"rgb(76,114,176)\", \"rgb(221,132,82)\", \"rgb(85,168,104)\", \"rgb(196,78,82)\", \"rgb(129,114,179)\", \"rgb(147,120,96)\", \"rgb(218,139,195)\", \"rgb(140,140,140)\", \"rgb(204,185,116)\", \"rgb(100,181,205)\"], \"font\": {\"color\": \"rgb(36,36,36)\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"rgb(234,234,242)\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"rgb(234,234,242)\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\"}, \"bgcolor\": \"rgb(234,234,242)\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"rgb(234,234,242)\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"showgrid\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"rgb(234,234,242)\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"showgrid\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"rgb(234,234,242)\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"showgrid\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"fillcolor\": \"rgb(67,103,167)\", \"line\": {\"width\": 0}, \"opacity\": 0.5}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\"}, \"bgcolor\": \"rgb(234,234,242)\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\"}}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\"}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"showgrid\": true, \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\"}}}, \"title\": {\"text\": \"Feature Importance Plot: Random Forests Regression\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Importance\"}}, \"yaxis\": {\"anchor\": \"x\", \"categoryorder\": \"total ascending\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Feature\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d181241d-a241-4ea4-8876-2652fb185398');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the plot below shows the feature importances of our features in a descending order\n",
    "\n",
    "figure = px.bar(feature_importances_df, x = 'Importance', y = 'Feature', orientation = 'h')\n",
    "figure.update_layout(title_text = 'Feature Importance Plot: Random Forests Regression', template = 'seaborn', height = 800, \\\n",
    "                     yaxis={'categoryorder':'total ascending'})\n",
    "figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
